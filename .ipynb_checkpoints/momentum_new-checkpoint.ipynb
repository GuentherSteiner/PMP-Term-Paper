{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can recall from critisicm regarding this presentation:\n",
    "\n",
    "- did not take the equal weighted as benchmark\n",
    "- use total return indices (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import required Packages ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Seaborn\n",
    "sb.set_style(\"ticks\")\n",
    "sb.mpl.rc(\"figure\", figsize=(16,8))\n",
    "sb.mpl.rc(\"font\", size=14)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "# little function for later\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawdata is direct import from excel\n",
    "\n",
    "# Import of excel data, sheet by sheet\n",
    "xls_ETF = pd.ExcelFile(\"1_Data/Data Clean TM/Data_ETFxIndex_stiched.xlsx\")\n",
    "xls_Inflation = pd.ExcelFile(\"1_Data/Data Clean TM/Data_Inflation.xlsx\")\n",
    "xls_Yield = pd.ExcelFile(\"1_Data/Data Clean TM/Yields_Clean_TM.xlsx\")\n",
    "xls_FX = pd.ExcelFile(\"1_Data/Data Clean TM/Data_FX_spot.xlsx\")\n",
    "\n",
    "ETF_raw = pd.DataFrame(pd.read_excel(xls_ETF))\n",
    "Inflation_raw = pd.DataFrame(pd.read_excel(xls_Inflation, 2))\n",
    "Yield_long_raw = pd.DataFrame(pd.read_excel(xls_Yield, 2))\n",
    "Yield_short_raw = pd.DataFrame(pd.read_excel(xls_Yield, 3))\n",
    "FX_raw = pd.DataFrame(pd.read_excel(xls_FX, 3))\n",
    "\n",
    "# keep a safe copy of the rawdata to compare the changes\n",
    "ETF = ETF_raw.copy()\n",
    "Inflation = Inflation_raw.copy()\n",
    "Yield_long = Yield_long_raw.copy()\n",
    "Yield_short = Yield_short_raw.copy()\n",
    "FX = FX_raw.copy()\n",
    "\n",
    "# Set date as index\n",
    "ETF.set_index(\"Datum\", inplace=True)\n",
    "Inflation.set_index(\"Datum\", inplace=True)\n",
    "Yield_long.set_index(\"Datum\", inplace=True)\n",
    "Yield_short.set_index(\"Datum\", inplace=True)\n",
    "FX.set_index(\"Dates\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns in which only text is and safe them separately --> ONLY RUN ONCE\n",
    "# ETF_text = ETF.iloc[0,:]\n",
    "# Yield_text = Yield.iloc[0,:]\n",
    "# Yield_short_text = Yield_short.iloc[0,:]\n",
    "# cpicore_text = cpicore.iloc[0:1,:]\n",
    "# ETF.drop([0], inplace = True)\n",
    "# Yield.drop([0], inplace = True)\n",
    "# Yield_short.drop([0], inplace = True)\n",
    "# cpicore.drop([0,1], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent infl – the average of the headline and core annual CPI inflation rate\n",
    "--> we don't have headline inflation\n",
    "\n",
    "\n",
    "Effective target infl - The effective inflation target is the mean of the target range announced or implied by the authorities plus an adjusted for past “target misses”, which is the last 3 years’ average gap between actual inflation and the target means\n",
    "--> we don't have target rates for all countries --> use 2.5 as target rate\n",
    "\n",
    "Formula: (1/n)*recent infl + ((n-1)/n)*effective target infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e12819c2dedb>:35: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.04\n",
      "<ipython-input-4-e12819c2dedb>:26: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-4-e12819c2dedb>:11: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-4-e12819c2dedb>:24: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.033\n",
      "<ipython-input-4-e12819c2dedb>:9: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.025\n",
      "<ipython-input-4-e12819c2dedb>:13: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-4-e12819c2dedb>:33: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.01\n",
      "<ipython-input-4-e12819c2dedb>:31: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-4-e12819c2dedb>:17: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-4-e12819c2dedb>:15: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-4-e12819c2dedb>:22: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n"
     ]
    }
   ],
   "source": [
    "# first we will take the difference between the effective target (mean) inflation and the actual inflation\n",
    "\n",
    "cpiheadline = Inflation.copy()\n",
    "\n",
    "eff_target_diff = pd.DataFrame(columns = cpiheadline.columns, index = cpiheadline.index)\n",
    "\n",
    "for i in eff_target_diff.columns:\n",
    "    if i == \"Australia\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.025\n",
    "    elif i == \"Canada\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"China\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Germany\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"France\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"UK\":\n",
    "        eff_target_diff.loc[:\"2003-11-28\",i] = cpiheadline.loc[:\"2003-11-28\",i] - 0.025\n",
    "        eff_target_diff.loc[\"2003-12-31\":,i] = cpiheadline.loc[\"2003-12-31\":,i] - 0.02\n",
    "    elif i == \"Italy\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Japan\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.033\n",
    "    elif i == \"Singapore\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"USA\":\n",
    "        eff_target_diff.loc[:\"2011-12-31\",i] = cpiheadline.loc[:\"2011-12-31\",i] - 0.0185\n",
    "        eff_target_diff.loc[\"2012-01-31\":,i] = cpiheadline.loc[\"2012-01-31\":,i] - 0.02\n",
    "    elif i == \"Spain\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Switzerland\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.01\n",
    "    elif i == \"India\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(eff_target_diff.loc[:\"2002-11-30\", \"Singapore\"])\n",
    "#np.nanmean(eff_target_diff.loc[\"2020-05-31\":, \"Singapore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-718e0d68af44>:15: RuntimeWarning: Mean of empty slice\n",
      "  inflation = np.nanmean(eff_target_diff.iloc[runner-36:runner, j])\n"
     ]
    }
   ],
   "source": [
    "# create the rolling 3-year average of the core inflation\n",
    "\n",
    "# first I have to set up an empty dictionary to store the rolling averages\n",
    "cpiheadline_avg = {}\n",
    "for i in cpiheadline.columns:\n",
    "    cpiheadline_avg[i] = []\n",
    "\n",
    "# next up we iterate over the cpicore data to get the index and safe them in the dictionary\n",
    "runner = len(cpiheadline.index)\n",
    "for i in cpiheadline.index:\n",
    "    if runner == 35:\n",
    "        break\n",
    "    \n",
    "    for j,k in enumerate(cpiheadline.columns):\n",
    "        inflation = np.nanmean(eff_target_diff.iloc[runner-36:runner, j])\n",
    "        cpiheadline_avg[k].insert(0, inflation)\n",
    "    runner -= 1\n",
    "    \n",
    "#cpiheadline_avg\n",
    "cpiheadline_avg_trimmed = pd.DataFrame(cpiheadline_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpiheadline_avg_trimmed # until here I checked several times whether it is correct and it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-90c02453a451>:21: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  formula_values.iloc[:,j+i*5] = (1/m)*cpiheadline_trimmed[k] +((m-1)/m)*cpiheadline_avg_trimmed[k]\n"
     ]
    }
   ],
   "source": [
    "# now we calculate the value formula:\n",
    "# (1/n)*recent inflation + ((n-1)/n)*effective target inflation for the years: 2, 5, 10, 20, 30\n",
    "\n",
    "# first we need to align the dataframes \n",
    "cpiheadline_trimmed = cpiheadline[35:]\n",
    "cpiheadline_avg_trimmed.set_index(cpiheadline_trimmed.index, inplace = True)\n",
    "\n",
    "# second we create an empty dictionary to fill with the calculations\n",
    "formula_values = {}\n",
    "x = 0\n",
    "for i in cpiheadline_trimmed.columns:\n",
    "    x += 1\n",
    "    for j in [2,5,10,20,30]:\n",
    "        formula_values[f\"{i},{j}\"] = []\n",
    "formula_values = pd.DataFrame(columns = formula_values.keys(), index = cpiheadline_trimmed.index)\n",
    "\n",
    "\n",
    "# now that we have the empty dictionary to fill, we start with caluclating the inflation expectation\n",
    "for i,k in enumerate (cpiheadline_trimmed.columns):\n",
    "    for j,m in enumerate([2,5,10,20,30]):\n",
    "        formula_values.iloc[:,j+i*5] = (1/m)*cpiheadline_trimmed[k] +((m-1)/m)*cpiheadline_avg_trimmed[k]\n",
    "        \n",
    "#formula_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have the issue that the Yield_clean data and the Inflation_clean data doesn't have the same sequence of countries\n",
    "# to avoid this we resort the Yield_clean data to fit the Inflation_clean data\n",
    "\n",
    "clean_names = [\"Germany\", \"France\",\"Spain\",\"Italy\",\"United Kingdom\", \"Switzerland\", \"China\", \"Australia\", \"Japan\", \"USA\", \"Canada\", \"Singapore\", \"India\"]\n",
    "\n",
    "# we split the dataframe into the different countries...\n",
    "Germany = Yield_long.iloc[:,:5]\n",
    "France = Yield_long.iloc[:,5:10]\n",
    "Spain = Yield_long.iloc[:,10:15]\n",
    "Italy = Yield_long.iloc[:,15:20]\n",
    "UK = Yield_long.iloc[:,20:25]\n",
    "Switzerland = Yield_long.iloc[:,25:30]\n",
    "China = Yield_long.iloc[:,30:35]\n",
    "Australia = Yield_long.iloc[:,35:40]\n",
    "Japan = Yield_long.iloc[:,40:45]\n",
    "USA = Yield_long.iloc[:,45:50]\n",
    "Canada = Yield_long.iloc[:,50:55]\n",
    "Singapore = Yield_long.iloc[:,55:60]\n",
    "India = Yield_long.iloc[:,60:]\n",
    "\n",
    "# ... and fusion them together to have the same order as the Inflation data (plus dividing by 100 to have same level as Inflation)\n",
    "Yields_aligned = [India, Singapore, Canada, USA, Japan, Australia, China, Switzerland, UK, Spain, France, Germany, Italy]\n",
    "Yields_aligned = pd.concat(Yields_aligned, axis=1)\n",
    "Yields_aligned = Yields_aligned /100\n",
    "#Yields_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a next step we adjust the yield data to have the same lookback as the other data\n",
    "\n",
    "Yield_trimmed = Yields_aligned[35:]\n",
    "\n",
    "Real_yield = pd.DataFrame(0, columns = formula_values.columns, index = formula_values.index)\n",
    "\n",
    "# now we take the difference between yield etf and inflation\n",
    "for i,k in enumerate(formula_values.columns):\n",
    "    for j,l in enumerate(formula_values.index):\n",
    "        Real_yield.iloc[j,i] = Yield_trimmed.iloc[j,i] - formula_values.iloc[j,i]\n",
    "#Real_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-32f040c4ca01>:7: RuntimeWarning: Mean of empty slice\n",
      "  temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n",
      "<ipython-input-10-32f040c4ca01>:8: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  Real_yield_avg.iloc[:,runner] = temp.values\n",
      "<ipython-input-10-32f040c4ca01>:7: RuntimeWarning: Mean of empty slice\n",
      "  temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>India</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Canada</th>\n",
       "      <th>USA</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Australia</th>\n",
       "      <th>China</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>UK</th>\n",
       "      <th>Spain</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Italy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-11-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038142</td>\n",
       "      <td>0.040897</td>\n",
       "      <td>0.049712</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>0.026126</td>\n",
       "      <td>0.043910</td>\n",
       "      <td>0.045212</td>\n",
       "      <td>0.037274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034024</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>0.043797</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.051624</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.042709</td>\n",
       "      <td>0.033574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033443</td>\n",
       "      <td>0.038607</td>\n",
       "      <td>0.045030</td>\n",
       "      <td>0.042133</td>\n",
       "      <td>0.035061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>0.021023</td>\n",
       "      <td>0.038475</td>\n",
       "      <td>0.041751</td>\n",
       "      <td>0.032091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-02-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.042106</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020968</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.037702</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.030862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030536</td>\n",
       "      <td>0.037642</td>\n",
       "      <td>0.039602</td>\n",
       "      <td>0.040662</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.050895</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.037697</td>\n",
       "      <td>0.041202</td>\n",
       "      <td>0.032165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>0.043538</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.022938</td>\n",
       "      <td>0.023062</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>-0.008969</td>\n",
       "      <td>0.010376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.021593</td>\n",
       "      <td>0.020613</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.012604</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>0.045688</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.021692</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>0.024872</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>0.025097</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>-0.011226</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>0.044692</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.020838</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>0.017069</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>-0.012827</td>\n",
       "      <td>0.005570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               India  Singapore    Canada       USA     Japan  Australia  \\\n",
       "Datum                                                                      \n",
       "2002-11-30       NaN   0.038142  0.040897  0.049712  0.045416   0.040049   \n",
       "2002-12-31       NaN   0.034024  0.035837  0.044641  0.043797   0.035000   \n",
       "2003-01-31       NaN   0.033443  0.038607  0.045030  0.042133   0.035061   \n",
       "2003-02-28       NaN   0.030761  0.036602  0.042970  0.042106   0.033406   \n",
       "2003-03-31       NaN   0.030536  0.037642  0.039602  0.040662   0.035846   \n",
       "...              ...        ...       ...       ...       ...        ...   \n",
       "2022-11-30  0.043538   0.016547  0.010547  0.021676  0.021544   0.022938   \n",
       "2022-12-31  0.045032   0.015152  0.009672  0.021593  0.020613   0.021749   \n",
       "2023-01-31  0.045688   0.014201  0.009618  0.021692  0.019527   0.019785   \n",
       "2023-02-28  0.044519   0.012698  0.009524  0.020977  0.018174   0.018527   \n",
       "2023-03-31  0.044692   0.011856  0.010074  0.020838  0.019278   0.017069   \n",
       "\n",
       "               China  Switzerland        UK     Spain    France   Germany  \\\n",
       "Datum                                                                       \n",
       "2002-11-30       NaN     0.023939  0.054983  0.026126  0.043910  0.045212   \n",
       "2002-12-31       NaN     0.021170  0.051624  0.022888  0.040268  0.042709   \n",
       "2003-01-31       NaN     0.021291  0.051239  0.021023  0.038475  0.041751   \n",
       "2003-02-28       NaN     0.020968  0.049642  0.020183  0.037702  0.040185   \n",
       "2003-03-31       NaN     0.023387  0.050895  0.021027  0.037697  0.041202   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "2022-11-30  0.023062     0.006303  0.002752  0.005886  0.013793 -0.008969   \n",
       "2022-12-31  0.024608     0.005594  0.001354  0.005306  0.012604 -0.010298   \n",
       "2023-01-31  0.024872     0.005352 -0.000396  0.006128  0.012105 -0.009448   \n",
       "2023-02-28  0.025097     0.003760 -0.001588  0.004677  0.010899 -0.011226   \n",
       "2023-03-31  0.028001     0.002783 -0.004108  0.003288  0.009248 -0.012827   \n",
       "\n",
       "               Italy  \n",
       "Datum                 \n",
       "2002-11-30  0.037274  \n",
       "2002-12-31  0.033574  \n",
       "2003-01-31  0.032091  \n",
       "2003-02-28  0.030862  \n",
       "2003-03-31  0.032165  \n",
       "...              ...  \n",
       "2022-11-30  0.010376  \n",
       "2022-12-31  0.007769  \n",
       "2023-01-31  0.005583  \n",
       "2023-02-28  0.006061  \n",
       "2023-03-31  0.005570  \n",
       "\n",
       "[245 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a final step we will average over the duration of the countries to get one average for each country\n",
    "\n",
    "Real_yield_avg = pd.DataFrame(columns = cpiheadline_avg_trimmed.columns, index = Real_yield.index)\n",
    "\n",
    "runner = 0\n",
    "for i in range(0, len(Yields_aligned.columns)-1, 5):\n",
    "    temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n",
    "    Real_yield_avg.iloc[:,runner] = temp.values\n",
    "    runner +=1\n",
    "    \n",
    "#Real_yield_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate computeSortWeights into python\n",
    "def compute_sort_weights(sort_variable, n_longs, n_shorts, long_high_values):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        list_of_longs = np.argpartition(-sort_variable, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(sort_variable, n_shorts)[:n_shorts]\n",
    "    else:\n",
    "        list_of_longs = np.argpartition(sort_variable, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(-sort_variable, n_shorts)[:n_shorts]\n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sort_weights_GPT(sort_variable, n_longs, n_shorts, long_high_values):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Count the number of non-NaN values in the sort_variable for the current row\n",
    "    non_nan_values = np.count_nonzero(~np.isnan(sort_variable))\n",
    "\n",
    "    # Set n_longs and n_shorts to the maximum possible value if there are less non-NaN values than n_longs + n_shorts\n",
    "    if non_nan_values < n_longs + n_shorts:\n",
    "        max_possible = non_nan_values // 2\n",
    "        n_longs = max_possible\n",
    "        n_shorts = max_possible\n",
    "\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        list_of_longs = np.argpartition(-sort_variable, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(sort_variable, n_shorts)[:n_shorts]\n",
    "    else:\n",
    "        list_of_longs = np.argpartition(sort_variable, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(-sort_variable, n_shorts)[:n_shorts]\n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we take the average of the three Swiss indices\n",
    "\n",
    "ETF_price = ETF.copy()\n",
    "\n",
    "# s1 = ETF_price[\"Switzerland 1\"]\n",
    "# s2 = ETF_price[\"Switzerland 2\"]\n",
    "# s3 = ETF_price[\"Switzerland 3\"]\n",
    "\n",
    "#ETF_price.drop([\"Switzerland 2\", \"Switzerland 3\"], axis = 1, inplace = True)\n",
    "#ETF_price.loc[\"2003-11-28\":,\"Switzerland 1\"] = (np.nanmean([s1.loc[\"2003-11-28\":], s2.loc[\"2003-11-28\":], s3.loc[\"2003-11-28\":]], axis = 0))\n",
    "#ETF_price.rename(columns={\"Switzerland 1\": \"Switzerland\"}, inplace = True)\n",
    "#ETF_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Monthly Returns out of ETF Prices\n",
    "ETF_returns = ETF_price.pct_change()\n",
    "ETF_ret = ETF_returns.tail(-1)\n",
    "ETF_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Weights for Momentum\n",
    "\n",
    "# Prep Work\n",
    "nAssets = len(ETF_price.columns) # 13 Countries\n",
    "nMonths = len(ETF_price) # 279 Months of returns (31.01.2000 - 31.03.2023)\n",
    "lookbackStart = 12\n",
    "lookbackEnd = 1\n",
    "firstMonth = lookbackStart + 1 # we can only start computing weights in 13.month bc we have 12 months lookback \n",
    "nLongs = 5\n",
    "nShorts = 5\n",
    "momLongWeights = np.zeros((nMonths, nAssets))\n",
    "momLSWeights = np.zeros((nMonths, nAssets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(firstMonth, nMonths):\n",
    "    pastReturns = np.divide(ETF_price.iloc[month - lookbackEnd, :], ETF_price.iloc[month - lookbackStart, :]) - 1\n",
    "    momLSWeights[month, :] = compute_sort_weights_GPT(pastReturns, nLongs, nShorts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleanup -> Returns in sync with weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start off by calculating the returns\n",
    "ETF_returns = ETF_price.pct_change()\n",
    "\n",
    "# here we convert the values to numeric in order to take the maximum afterwards\n",
    "ETF_returns = ETF_returns.apply(pd.to_numeric)\n",
    "\n",
    "# here we aggregate the past 11 months returns\n",
    "past_11 = (ETF_returns+1).rolling(11).apply(np.prod)-1 # accumulate returns over 11 months \n",
    "past_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>Germany.1</th>\n",
       "      <th>Germany.2</th>\n",
       "      <th>Germany.3</th>\n",
       "      <th>Germany.4</th>\n",
       "      <th>France</th>\n",
       "      <th>France.1</th>\n",
       "      <th>France.2</th>\n",
       "      <th>France.3</th>\n",
       "      <th>France.4</th>\n",
       "      <th>...</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Singapore.1</th>\n",
       "      <th>Singapore.2</th>\n",
       "      <th>Singapore.3</th>\n",
       "      <th>Singapore.4</th>\n",
       "      <th>India</th>\n",
       "      <th>India.1</th>\n",
       "      <th>India.2</th>\n",
       "      <th>India.3</th>\n",
       "      <th>India.4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>4.264</td>\n",
       "      <td>4.992</td>\n",
       "      <td>5.429</td>\n",
       "      <td>6.172</td>\n",
       "      <td>6.114</td>\n",
       "      <td>4.282</td>\n",
       "      <td>4.879</td>\n",
       "      <td>5.634</td>\n",
       "      <td>6.361</td>\n",
       "      <td>6.152</td>\n",
       "      <td>...</td>\n",
       "      <td>2.247</td>\n",
       "      <td>4.123</td>\n",
       "      <td>4.677</td>\n",
       "      <td>4.624</td>\n",
       "      <td>4.606</td>\n",
       "      <td>10.280</td>\n",
       "      <td>10.778</td>\n",
       "      <td>11.516</td>\n",
       "      <td>12.467</td>\n",
       "      <td>12.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>4.473</td>\n",
       "      <td>5.251</td>\n",
       "      <td>5.614</td>\n",
       "      <td>6.233</td>\n",
       "      <td>6.147</td>\n",
       "      <td>4.513</td>\n",
       "      <td>5.162</td>\n",
       "      <td>5.799</td>\n",
       "      <td>6.378</td>\n",
       "      <td>6.200</td>\n",
       "      <td>...</td>\n",
       "      <td>2.446</td>\n",
       "      <td>4.176</td>\n",
       "      <td>4.586</td>\n",
       "      <td>4.543</td>\n",
       "      <td>4.529</td>\n",
       "      <td>10.106</td>\n",
       "      <td>10.463</td>\n",
       "      <td>11.141</td>\n",
       "      <td>12.033</td>\n",
       "      <td>11.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>4.564</td>\n",
       "      <td>5.169</td>\n",
       "      <td>5.583</td>\n",
       "      <td>6.004</td>\n",
       "      <td>5.928</td>\n",
       "      <td>4.529</td>\n",
       "      <td>5.127</td>\n",
       "      <td>5.736</td>\n",
       "      <td>6.261</td>\n",
       "      <td>6.080</td>\n",
       "      <td>...</td>\n",
       "      <td>2.492</td>\n",
       "      <td>3.887</td>\n",
       "      <td>4.382</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.334</td>\n",
       "      <td>9.602</td>\n",
       "      <td>9.955</td>\n",
       "      <td>10.604</td>\n",
       "      <td>11.660</td>\n",
       "      <td>11.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>4.499</td>\n",
       "      <td>4.957</td>\n",
       "      <td>5.284</td>\n",
       "      <td>5.743</td>\n",
       "      <td>5.659</td>\n",
       "      <td>4.497</td>\n",
       "      <td>4.917</td>\n",
       "      <td>5.430</td>\n",
       "      <td>5.941</td>\n",
       "      <td>5.772</td>\n",
       "      <td>...</td>\n",
       "      <td>2.584</td>\n",
       "      <td>3.853</td>\n",
       "      <td>4.376</td>\n",
       "      <td>4.338</td>\n",
       "      <td>4.325</td>\n",
       "      <td>10.192</td>\n",
       "      <td>10.373</td>\n",
       "      <td>11.063</td>\n",
       "      <td>11.710</td>\n",
       "      <td>11.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>4.657</td>\n",
       "      <td>5.106</td>\n",
       "      <td>5.369</td>\n",
       "      <td>5.834</td>\n",
       "      <td>5.619</td>\n",
       "      <td>4.634</td>\n",
       "      <td>5.054</td>\n",
       "      <td>5.486</td>\n",
       "      <td>5.903</td>\n",
       "      <td>5.774</td>\n",
       "      <td>...</td>\n",
       "      <td>2.918</td>\n",
       "      <td>3.855</td>\n",
       "      <td>4.342</td>\n",
       "      <td>4.306</td>\n",
       "      <td>4.294</td>\n",
       "      <td>9.314</td>\n",
       "      <td>9.851</td>\n",
       "      <td>10.695</td>\n",
       "      <td>11.211</td>\n",
       "      <td>11.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>1.899</td>\n",
       "      <td>1.984</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.287</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.097</td>\n",
       "      <td>3.263</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.177</td>\n",
       "      <td>2.948</td>\n",
       "      <td>7.001</td>\n",
       "      <td>7.269</td>\n",
       "      <td>7.392</td>\n",
       "      <td>7.444</td>\n",
       "      <td>7.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1.899</td>\n",
       "      <td>1.984</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.287</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.097</td>\n",
       "      <td>3.263</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.177</td>\n",
       "      <td>2.948</td>\n",
       "      <td>7.001</td>\n",
       "      <td>7.269</td>\n",
       "      <td>7.392</td>\n",
       "      <td>7.444</td>\n",
       "      <td>7.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>1.899</td>\n",
       "      <td>1.984</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.287</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.097</td>\n",
       "      <td>3.263</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.177</td>\n",
       "      <td>2.948</td>\n",
       "      <td>7.001</td>\n",
       "      <td>7.269</td>\n",
       "      <td>7.392</td>\n",
       "      <td>7.444</td>\n",
       "      <td>7.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>1.899</td>\n",
       "      <td>1.984</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.287</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.097</td>\n",
       "      <td>3.263</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.177</td>\n",
       "      <td>2.948</td>\n",
       "      <td>7.001</td>\n",
       "      <td>7.269</td>\n",
       "      <td>7.392</td>\n",
       "      <td>7.444</td>\n",
       "      <td>7.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>1.899</td>\n",
       "      <td>1.984</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.287</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.097</td>\n",
       "      <td>3.263</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.177</td>\n",
       "      <td>2.948</td>\n",
       "      <td>7.001</td>\n",
       "      <td>7.269</td>\n",
       "      <td>7.392</td>\n",
       "      <td>7.444</td>\n",
       "      <td>7.495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Germany  Germany.1  Germany.2  Germany.3  Germany.4  France  \\\n",
       "Datum                                                                     \n",
       "1999-12-31    4.264      4.992      5.429      6.172      6.114   4.282   \n",
       "2000-01-31    4.473      5.251      5.614      6.233      6.147   4.513   \n",
       "2000-02-29    4.564      5.169      5.583      6.004      5.928   4.529   \n",
       "2000-03-31    4.499      4.957      5.284      5.743      5.659   4.497   \n",
       "2000-04-28    4.657      5.106      5.369      5.834      5.619   4.634   \n",
       "...             ...        ...        ...        ...        ...     ...   \n",
       "2022-11-30    1.899      1.984      2.117      2.306      2.148   2.084   \n",
       "2022-12-30    1.899      1.984      2.117      2.306      2.148   2.084   \n",
       "2023-01-31    1.899      1.984      2.117      2.306      2.148   2.084   \n",
       "2023-02-28    1.899      1.984      2.117      2.306      2.148   2.084   \n",
       "2023-03-31    1.899      1.984      2.117      2.306      2.148   2.084   \n",
       "\n",
       "            France.1  France.2  France.3  France.4  ...  Singapore  \\\n",
       "Datum                                               ...              \n",
       "1999-12-31     4.879     5.634     6.361     6.152  ...      2.247   \n",
       "2000-01-31     5.162     5.799     6.378     6.200  ...      2.446   \n",
       "2000-02-29     5.127     5.736     6.261     6.080  ...      2.492   \n",
       "2000-03-31     4.917     5.430     5.941     5.772  ...      2.584   \n",
       "2000-04-28     5.054     5.486     5.903     5.774  ...      2.918   \n",
       "...              ...       ...       ...       ...  ...        ...   \n",
       "2022-11-30     2.287     2.639     3.091     3.027  ...      3.097   \n",
       "2022-12-30     2.287     2.639     3.091     3.027  ...      3.097   \n",
       "2023-01-31     2.287     2.639     3.091     3.027  ...      3.097   \n",
       "2023-02-28     2.287     2.639     3.091     3.027  ...      3.097   \n",
       "2023-03-31     2.287     2.639     3.091     3.027  ...      3.097   \n",
       "\n",
       "            Singapore.1  Singapore.2  Singapore.3  Singapore.4   India  \\\n",
       "Datum                                                                    \n",
       "1999-12-31        4.123        4.677        4.624        4.606  10.280   \n",
       "2000-01-31        4.176        4.586        4.543        4.529  10.106   \n",
       "2000-02-29        3.887        4.382        4.346        4.334   9.602   \n",
       "2000-03-31        3.853        4.376        4.338        4.325  10.192   \n",
       "2000-04-28        3.855        4.342        4.306        4.294   9.314   \n",
       "...                 ...          ...          ...          ...     ...   \n",
       "2022-11-30        3.263        3.422        3.177        2.948   7.001   \n",
       "2022-12-30        3.263        3.422        3.177        2.948   7.001   \n",
       "2023-01-31        3.263        3.422        3.177        2.948   7.001   \n",
       "2023-02-28        3.263        3.422        3.177        2.948   7.001   \n",
       "2023-03-31        3.263        3.422        3.177        2.948   7.001   \n",
       "\n",
       "            India.1  India.2  India.3  India.4  \n",
       "Datum                                           \n",
       "1999-12-31   10.778   11.516   12.467   12.214  \n",
       "2000-01-31   10.463   11.141   12.033   11.808  \n",
       "2000-02-29    9.955   10.604   11.660   11.426  \n",
       "2000-03-31   10.373   11.063   11.710   11.536  \n",
       "2000-04-28    9.851   10.695   11.211   11.057  \n",
       "...             ...      ...      ...      ...  \n",
       "2022-11-30    7.269    7.392    7.444    7.495  \n",
       "2022-12-30    7.269    7.392    7.444    7.495  \n",
       "2023-01-31    7.269    7.392    7.444    7.495  \n",
       "2023-02-28    7.269    7.392    7.444    7.495  \n",
       "2023-03-31    7.269    7.392    7.444    7.495  \n",
       "\n",
       "[280 rows x 65 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yield_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for carry we will now calculate the differences between the long-term yields (2,5,10,20,30) and short-term yields (1M, 3M)\n",
    "# we will create a dataframe for the 1M and the 3M\n",
    "\n",
    "Carry_3m = pd.DataFrame(columns = Yield_long.columns, index = Yield_long.index)\n",
    "avg_Carry_3m = pd.DataFrame(0, columns = Yield_short.columns, index = Yield_short.index)\n",
    "\n",
    "# next we will iterate through all the columns of the yields and substract the short-term rate\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i in range(0,len(Yield_short.columns)-1):\n",
    "    if counter == 5:\n",
    "        counter = 0\n",
    "        runner += 2\n",
    "    counter += 1\n",
    "    Carry_3m.iloc[:,i] = Yield_long.iloc[:,i] - Yield_short.iloc[:,runner+1]\n",
    "    \n",
    "\n",
    "for i in range(0,len(Yield_short.columns)-1):\n",
    "    for j in range(5):\n",
    "        Carry_3m.iloc[:,i+j] = Yield_long.iloc[:,i+j] - Yield_short.iloc[:,i]\n",
    "    \n",
    "\n",
    "# # next we will equal weight the carry signal among the countries\n",
    "# Carry_1m.iloc[2:66,30:35] = 0\n",
    "\n",
    "# runner = 0\n",
    "# for i in range(0,len(Carry_1m.columns)-1, 5):\n",
    "#     avg_Carry_1m.iloc[:,runner] = np.nanmean([Carry_1m.iloc[:,i], Carry_1m.iloc[:,i+1], Carry_1m.iloc[:,i+2], Carry_1m.iloc[:,i+3], Carry_1m.iloc[:,i+4]], axis = 0)\n",
    "#     avg_Carry_3m.iloc[:,runner] = np.nanmean([Carry_3m.iloc[:,i], Carry_3m.iloc[:,i+1], Carry_3m.iloc[:,i+2], Carry_3m.iloc[:,i+3], Carry_3m.iloc[:,i+4]], axis = 0)\n",
    "#     runner += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "# # change data values from object to float\n",
    "# avg_Carry_1m = avg_Carry_1m.apply(pd.to_numeric)\n",
    "# avg_Carry_3m = avg_Carry_3m.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carry_3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for carry we will now calculate the differences between the long-term yields (2,5,10,20,30) and short-term yields (1M, 3M)\n",
    "# we will create a dataframe for the 1M and the 3M\n",
    "\n",
    "Carry_1m = pd.DataFrame(columns = Yield.columns, index = Yield.index)\n",
    "Carry_3m = pd.DataFrame(columns = Yield.columns, index = Yield.index)\n",
    "avg_Carry_1m = pd.DataFrame(0, columns = countries, index = Yield.index)\n",
    "avg_Carry_3m = pd.DataFrame(0, columns = countries, index = Yield.index)\n",
    "\n",
    "# next we will iterate through all the columns of the yields and substract the short-term rate\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i,k in enumerate(Yield.columns):\n",
    "    if counter == 5:\n",
    "        counter = 0\n",
    "        runner += 2\n",
    "    counter += 1\n",
    "    Carry_1m.iloc[:,i] = Yield.iloc[:,i] - Yield_short.iloc[:,runner]\n",
    "    Carry_3m.iloc[:,i] = Yield.iloc[:,i] - Yield_short.iloc[:,runner+1]\n",
    "    \n",
    "# next we will equal weight the carry signal among the countries\n",
    "for i in range(len(countries)):\n",
    "    j = 0\n",
    "    while j != 5:\n",
    "        avg_Carry_1m.iloc[:,i] += 1/5 * Carry_1m.iloc[:,i+j]\n",
    "        avg_Carry_3m.iloc[:,i] += 1/5 * Carry_3m.iloc[:,i+j]\n",
    "        j += 1\n",
    "        \n",
    "# change data values from object to float\n",
    "avg_Carry_1m = avg_Carry_1m.apply(pd.to_numeric)\n",
    "avg_Carry_3m = avg_Carry_3m.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carry_1m.iloc[2:66,30:35] = 1\n",
    "Yield.iloc[2:80,30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.nanmean([Carry_1m.iloc[0:2,0], Carry_1m.iloc[0:2,1]], axis = 0)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carry_1m.iloc[0:2,0].sub(np.nan, fill_value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort function to create the buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmp_sort(pandas_DataFrame, nMax):\n",
    "    top_bucket = {}\n",
    "    bottom_bucket = {}\n",
    "    for i,k in enumerate(pandas_DataFrame.index):\n",
    "        top_bucket[k] = []\n",
    "        bottom_bucket[k] = []\n",
    "        a = pandas_DataFrame.iloc[i]\n",
    "        for j in range(5):\n",
    "            x = a.idxmax()\n",
    "            y = a.idxmin()\n",
    "            if isNaN(x) and isNaN(y):\n",
    "                break\n",
    "            top_bucket[k].append(x)\n",
    "            bottom_bucket[k].append(y)\n",
    "            a = a.drop([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bucket = {}\n",
    "bottom_bucket = {}\n",
    "for i,k in enumerate(avg_yield_countries.index):\n",
    "    top_bucket[k] = []\n",
    "    bottom_bucket[k] = []\n",
    "    a = avg_yield_countries.iloc[i]\n",
    "    for i in range(3):\n",
    "        x = a.idxmax()\n",
    "        y = a.idxmin()\n",
    "        if isNaN(x):\n",
    "            continue\n",
    "        else:\n",
    "            top_bucket[k].append(x)\n",
    "            a = a.drop(x)\n",
    "        if isNaN(y):\n",
    "            continue\n",
    "        else:\n",
    "            bottom_bucket[k].append(y)\n",
    "            a = a.drop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_bucket)\n",
    "print(bottom_bucket)\n",
    "\n",
    "# avg_yield_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = avg_Carry_1m.iloc[0].drop([\"Switzerland\", np.nan])\n",
    "avg_Carry_1m.iloc[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = avg_yield_countries.iloc[0,2]\n",
    "b = avg_yield_countries.iloc[0,4]\n",
    "np.isnan([\"a\",b]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "p.append(np.nan)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut Momentum Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude Trading Days column and MSCI_EU Benchmark to have only Momentum columns\n",
    "prices = df.loc[:,\"Healthcare\":\"Real_estate\"]\n",
    "prices.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Monthly returns\n",
    "mtl_ret = prices.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "mtl_ret\n",
    "\n",
    "past_11 = (mtl_ret+1).rolling(11).apply(np.prod)-1 # accumulate returns over 11 months \n",
    "past_11.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining formation date <-  where portfolio gets created\n",
    "formation = dt.datetime(1999, 12, 31, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MeasurementDate <- up to last date of month before formation date\n",
    "end_measurement = formation - MonthEnd(1)\n",
    "end_measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Past 12 Month performance without most recent month <- in this case Jan, Feb, Mar, Apr, Jun, Jul, Sep, Oct, Nov but not December!\n",
    "ret_12 = past_11.loc[end_measurement]\n",
    "ret_12 = ret_12.reset_index()\n",
    "ret_12.rename(columns={ ret_12.columns[1]: \"returns\" }, inplace = True)\n",
    "ret_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_12 = ret_12.sort_values([\"returns\"], ascending=False)\n",
    "ret_12[\"bucket\"] = [2,2,2,2,2,1,0,0,0,0,0] # Make three buckets\n",
    "ret_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create winners and loser list based on bucket\n",
    "winners = ret_12[ret_12.bucket == 2]\n",
    "losers = ret_12[ret_12.bucket == 0]\n",
    "winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the winner and loser returns over the last 12 months excluding the most recent month\n",
    "winnerret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(winners[\"index\"])]\n",
    "loserret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(losers[\"index\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Momentumprofit = winnerret.mean() - loserret.mean()\n",
    "Momentumprofit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalising this Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(pandas_df, index=\"Date\", prices_start='Healthcare', prices_end='Real_estate', resample_freq='M', lookback=11):\n",
    "    print(pandas_df.isnull().values.any())\n",
    "    df = pandas_df.set_index(index, inplace=False)\n",
    "    prices = df.loc[:,prices_start:prices_end]\n",
    "    mtl_ret = prices.pct_change().resample(resample_freq).agg(lambda x: (1+x).prod()-1)\n",
    "    past_11 = (mtl_ret+1).rolling(lookback).apply(np.prod)-1\n",
    "    return prices, mtl_ret, past_11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = dff.set_index(\"Date\", inplace = False)\n",
    "x = dfff.resample(\"M\")\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test out the data_cleaner function\n",
    "\n",
    "prices, mtl_ret, past_11 = data_cleaner(dff, lookback = 3, resample_freq= 'BM')\n",
    "print(f'\\nprices:\\n {prices}, \\nmonthly_return:\\n {mtl_ret}, \\npast_11:\\n {past_11}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_11.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(formation, past_11, num_l_s=5):\n",
    "    end_measurement = formation - MonthEnd(1)\n",
    "    ret_12 = past_11.loc[end_measurement]\n",
    "    ret_12 = ret_12.reset_index()\n",
    "    ret_12.rename(columns={ ret_12.columns[1]: \"returns\" }, inplace = True)\n",
    "    ret_12 = ret_12.sort_values([\"returns\"], ascending=False)\n",
    "    \n",
    "    middle = 11-2*num_l_s\n",
    "    l_s = []\n",
    "    for i in range(num_l_s):\n",
    "        l_s.append(2)\n",
    "    for i in range(middle):\n",
    "        l_s.append(1)\n",
    "    for i in range(num_l_s):\n",
    "        l_s.append(0)\n",
    "    ret_12[\"bucket\"] = l_s # Make arbitrary number of buckets\n",
    "    \n",
    "    winners = ret_12[ret_12.bucket == 2]\n",
    "    losers = ret_12[ret_12.bucket == 0]\n",
    "    winnerret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(winners[\"index\"])]\n",
    "    loserret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(losers[\"index\"])]\n",
    "    Momentumprofit = winnerret.mean() - loserret.mean()\n",
    "    return Momentumprofit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation = dt.datetime(1999, 12, 31, 0, 0)\n",
    "momentum(formation, past_11) # has to be identical with [35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarker(pandas_df, profits_list):\n",
    "    dff = pandas_df.set_index(\"Date\", inplace=False)\n",
    "    \n",
    "    benchmark = dff[[\"MSCI_EU\"]]\n",
    "    benchmark = benchmark.loc[\"1999-12-31 00:00:00\":\"2022-09-30 00:00:00\"]\n",
    "    \n",
    "    bm_mtl_ret = mtl_ret = benchmark.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "    comparison = pd.DataFrame(bm_mtl_ret)\n",
    "    comparison[\"mom_ret\"] = profits_list\n",
    "    comparison.rename(columns={ comparison.columns[0]: \"bench_ret\" }, inplace = True)\n",
    "    comparison[\"bench_indexed\"] = comparison[\"bench_ret\"].add(1).cumprod()\n",
    "    comparison[\"mom_indexed\"] = comparison[\"mom_ret\"].add(1).cumprod()\n",
    "    print(comparison)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(comparison.index,comparison.mom_indexed, label=\"Momentum\", color=\"red\")\n",
    "    ax.plot(comparison.index,comparison.bench_indexed, label=\"MSCI EU\", color=\"blue\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_ylabel('Monthly Returns')\n",
    "    ax.set_title(\"Momentum long/short 5 sectors monthly rebalancing vs MSCI EU, indexed 31.12.1999\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop for every month  starting at formation date -> creates df with all these dates\n",
    "for i in range(273): # Eig wären es 273 Monate zwischen 31.12.1999 und 31.12.2022 -> stimmt irgendwie ned ganz aber lauft jetzt halt so bis endi august\n",
    "    print(formation + MonthEnd(i))\n",
    "\n",
    "#wären es nicht 276 Monate? has mit emene Zeitspannen-rechner usgrechnet --> gahd ets bis endi november 2022\n",
    "for i in range(276):\n",
    "    print(formation + MonthEnd(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop for storing the profits and the realized dates of the momentum strategy\n",
    "profits = []\n",
    "dates = []\n",
    "\n",
    "'''\n",
    "for i in range(273):\n",
    "    profits.append(momentum(formation + MonthEnd(i)))\n",
    "    dates.append(formation + MonthEnd(i))\n",
    "'''\n",
    "\n",
    "#version 2.0 (da gahds nume bis 274 --> gid en error wenn en monet meh nimmsch)\n",
    "for i in range(274):\n",
    "    profits.append(momentum(formation + MonthEnd(i), past_11))\n",
    "    dates.append(formation + MonthEnd(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarker(df, profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = pd.DataFrame({\"Dates\": dates,\"Profits\": profits})\n",
    "mom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = df[[\"MSCI_EU\"]]\n",
    "benchmark = benchmark.loc[\"1999-12-31 00:00:00\":\"2022-09-30 00:00:00\"]\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_mtl_ret = mtl_ret = benchmark.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "bm_mtl_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare momentum result vs benchmark\n",
    "comparison = pd.DataFrame(bm_mtl_ret)\n",
    "comparison[\"mom_ret\"] = profits\n",
    "comparison.rename(columns={ comparison.columns[0]: \"bench_ret\" }, inplace = True)\n",
    "comparison[\"bench_indexed\"] = comparison[\"bench_ret\"].add(1).cumprod()\n",
    "comparison[\"mom_indexed\"] = comparison[\"mom_ret\"].add(1).cumprod()\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(comparison.index,comparison.mom_indexed, label=\"Momentum\", color=\"red\")\n",
    "ax.plot(comparison.index,comparison.bench_indexed, label=\"MSCI EU\", color=\"blue\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_ylabel('Monthly Returns')\n",
    "ax.set_title(\"Momentum long/short 5 sectors monthly rebalancing vs MSCI EU, indexed 31.12.1999\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa336b74a8cbeead930f17f553be49714fc6c4491fbee50d1179d377ec590ae0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
