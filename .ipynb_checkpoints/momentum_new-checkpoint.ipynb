{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can recall from critisicm regarding this presentation:\n",
    "\n",
    "- did not take the equal weighted as benchmark\n",
    "- use total return indices (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import required Packages ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import math\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Seaborn\n",
    "sb.set_style(\"ticks\")\n",
    "sb.mpl.rc(\"figure\", figsize=(16,8))\n",
    "sb.mpl.rc(\"font\", size=14)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "# little function for later\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotstyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn plot style ticks to have nicer looking plots\n",
    "sb.set_style(\"ticks\")\n",
    "sb.mpl.rc(\"figure\", figsize=(16,8))\n",
    "sb.mpl.rc(\"font\", size=14)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawdata is direct import from excel\n",
    "\n",
    "# Import of excel data, sheet by sheet\n",
    "xls_ETF = pd.ExcelFile(\"1_Data/Data Clean TM/Data_ETFxIndex_stiched.xlsx\")\n",
    "xls_Inflation = pd.ExcelFile(\"1_Data/Data Clean TM/Data_Inflation.xlsx\")\n",
    "xls_Yield = pd.ExcelFile(\"1_Data/Data Clean TM/Yields_Clean_TM.xlsx\")\n",
    "xls_FX = pd.ExcelFile(\"1_Data/Data Clean TM/Data_FX_spot.xlsx\")\n",
    "\n",
    "ETF_raw = pd.DataFrame(pd.read_excel(xls_ETF))\n",
    "Inflation_raw = pd.DataFrame(pd.read_excel(xls_Inflation, 2))\n",
    "Yield_long_raw = pd.DataFrame(pd.read_excel(xls_Yield, 2))\n",
    "Yield_short_raw = pd.DataFrame(pd.read_excel(xls_Yield, 3))\n",
    "FX_raw = pd.DataFrame(pd.read_excel(xls_FX, 4))\n",
    "\n",
    "# keep a safe copy of the rawdata to compare the changes\n",
    "ETF = ETF_raw.copy()\n",
    "Inflation = Inflation_raw.copy()\n",
    "Yield_long = Yield_long_raw.copy()\n",
    "Yield_short = Yield_short_raw.copy()\n",
    "FX = FX_raw.copy()\n",
    "\n",
    "# Set date as index\n",
    "ETF.set_index(\"Datum\", inplace=True)\n",
    "Inflation.set_index(\"Datum\", inplace=True)\n",
    "Yield_long.set_index(\"Datum\", inplace=True)\n",
    "Yield_short.set_index(\"Datum\", inplace=True)\n",
    "FX.set_index(\"Dates\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns in which only text is and safe them separately --> ONLY RUN ONCE\n",
    "# ETF_text = ETF.iloc[0,:]\n",
    "# Yield_text = Yield.iloc[0,:]\n",
    "# Yield_short_text = Yield_short.iloc[0,:]\n",
    "# cpicore_text = cpicore.iloc[0:1,:]\n",
    "# ETF.drop([0], inplace = True)\n",
    "# Yield.drop([0], inplace = True)\n",
    "# Yield_short.drop([0], inplace = True)\n",
    "# cpicore.drop([0,1], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tCost = 0.005 # Needs to be discussed !!\n",
    "FX_ret = FX.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTurnover(previousWeights, newWeights, assetReturns, Rf):\n",
    "    \"\"\"\n",
    "    Computes turnover by comparing the previous and the new target weights \n",
    "    of the portfolio, accounting for the returns on the assets. The function \n",
    "    also computes the portfolio return excluding transaction costs, Rp. \n",
    "\n",
    "    Parameters:\n",
    "        previousWeights (array-like): previous target weights of the portfolio\n",
    "        newWeights (array-like): new target weights of the portfolio\n",
    "        assetReturns (array-like): returns on the assets\n",
    "        Rf (float): risk-free rate of return\n",
    "\n",
    "    Returns:\n",
    "        turnover (float): turnover\n",
    "        Rp (float): portfolio return excluding transaction costs\n",
    "    \"\"\"\n",
    "\n",
    "    Rp = np.sum(np.multiply(previousWeights, assetReturns)) + (1 - np.sum(previousWeights)) * Rf\n",
    "    valuePerAsset = previousWeights * (1 + assetReturns)\n",
    "    currentWeights = valuePerAsset / (1 + Rp)\n",
    "    turnover = np.sum(np.abs(newWeights - currentWeights))\n",
    "\n",
    "    return turnover, Rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_performance(xs_returns, rf, factor_xs_returns, annualization_factor, txt):\n",
    "#     # Compute total returns\n",
    "#     n_assets = xs_returns.shape[1]\n",
    "#     total_returns = xs_returns + rf * np.ones((xs_returns.shape[0], n_assets))\n",
    "\n",
    "#     # Compute the terminal value of the portfolios to get the geometric mean\n",
    "#     # return per period\n",
    "#     n_periods = xs_returns.shape[0]\n",
    "#     final_pf_val_rf = np.prod(1 + rf)\n",
    "#     final_pf_val_total_ret = np.prod(1 + total_returns)\n",
    "#     geom_avg_rf = 100 * ((final_pf_val_rf ** (annualization_factor / n_periods)) - 1)\n",
    "#     geom_avg_total_return = 100 * ((final_pf_val_total_ret ** (annualization_factor / n_periods)) - 1)\n",
    "#     geom_avg_xs_return = geom_avg_total_return - geom_avg_rf\n",
    "\n",
    "#     # Regress returns on benchmark to get alpha and factor exposures\n",
    "#     X = np.column_stack((np.ones(n_periods), factor_xs_returns))\n",
    "#     b = np.linalg.lstsq(X, xs_returns, rcond=None)[0]\n",
    "#     betas = b[1:, :]\n",
    "\n",
    "#     # Based on the regression estimates, compute the total return on the passive\n",
    "#     # alternative and the annualized alpha\n",
    "#     bm_ret = np.dot(factor_xs_returns, betas) + rf * np.ones((n_periods, n_assets))\n",
    "#     final_pf_val_bm = np.prod(1 + bm_ret)\n",
    "#     geom_avg_bm_return = 100 * ((final_pf_val_bm ** (annualization_factor / n_periods)) - 1)\n",
    "#     alpha_geometric = geom_avg_total_return - geom_avg_bm_return\n",
    "\n",
    "#     # Rescale the returns to be in percentage points\n",
    "#     xs_returns = 100 * xs_returns\n",
    "#     total_returns = 100 * total_returns\n",
    "\n",
    "#     # Compute first three autocorrelations\n",
    "#     ac1 = np.diag(np.corrcoef(xs_returns[:-1, :], xs_returns[1:, :], rowvar=False)[:n_assets, n_assets:])\n",
    "#     ac2 = np.diag(np.corrcoef(xs_returns[:-2, :], xs_returns[2:, :], rowvar=False)[:n_assets, n_assets:])\n",
    "#     ac3 = np.diag(np.corrcoef(xs_returns[:-3, :], xs_returns[3:, :], rowvar=False)[:n_assets, n_assets:])\n",
    "\n",
    "#     # Report the statistics\n",
    "#     print(f'Performance Statistics for {txt}')\n",
    "#     arithm_avg_total_return = annualization_factor * np.mean(total_returns)\n",
    "#     arithm_avg_xs_return = annualization_factor * np.mean(xs_returns)\n",
    "#     std_xs_returns = np.sqrt(annualization_factor) * np.std(xs_returns, ddof=1)\n",
    "#     sharpe_arithmetic = arithm_avg_xs_return / std_xs_returns\n",
    "#     print(f'ArithmAvgTotalReturn: {arithm_avg_total_return}')\n",
    "#     print(f'ArithmAvgXsReturn: {arithm_avg_xs_return}')\n",
    "#     print(f'StdXsReturns: {std_xs_returns}')\n",
    "#     print(f'SharpeArithmetic: {sharpe_arithmetic}')\n",
    "#     print(f'GeomAvgTotalReturn: {geom_avg_total_return}')\n",
    "#     print(f'GeomAvgXsReturn: {geom_avg_xs_return}')\n",
    "#     sharpe_geometric = geom_avg_xs_return / std_xs_returns\n",
    "#     print(f'SharpeGeometric: {sharpe_geometric}')\n",
    "#     print(f'MinXsReturn: {np.min(xs_returns, axis=0)}')\n",
    "#     print(f'MaxXsReturn: {np.max(xs_returns, axis=0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance2(xs_returns, rf, factor_xs_returns, annualization_factor, txt):\n",
    "    # Compute total returns\n",
    "    n_assets = xs_returns.shape[1]\n",
    "    rf_reshaped = rf.values.reshape((-1,1))\n",
    "    total_returns = xs_returns + rf_reshaped * np.ones((xs_returns.shape[0], n_assets))\n",
    "\n",
    "    # Compute the terminal value of the portfolios to get the geometric mean\n",
    "    # return per period\n",
    "    n_periods = xs_returns.shape[0]\n",
    "    final_pf_val_rf = np.prod(1 + rf_reshaped)\n",
    "    final_pf_val_total_ret = np.prod(1 + total_returns)\n",
    "    geom_avg_rf = 100 * ((final_pf_val_rf ** (annualization_factor / n_periods)) - 1)\n",
    "    geom_avg_total_return = 100 * ((final_pf_val_total_ret ** (annualization_factor / n_periods)) - 1)\n",
    "    geom_avg_xs_return = geom_avg_total_return - geom_avg_rf\n",
    "\n",
    "    # Regress returns on benchmark to get alpha and factor exposures\n",
    "    X = np.column_stack((np.ones(n_periods), factor_xs_returns))\n",
    "    b = np.linalg.lstsq(X, xs_returns, rcond=None)[0]\n",
    "    betas = b[1:, :]\n",
    "\n",
    "    # Based on the regression estimates, compute the total return on the passive\n",
    "    # alternative and the annualized alpha\n",
    "    bm_ret = np.dot(np.array(factor_xs_returns).reshape(-1, 1), betas) + rf_reshaped * np.ones((n_periods, n_assets))\n",
    "    final_pf_val_bm = np.prod(1 + bm_ret)\n",
    "    geom_avg_bm_return = 100 * ((final_pf_val_bm ** (annualization_factor / n_periods)) - 1)\n",
    "    alpha_geometric = geom_avg_total_return - geom_avg_bm_return\n",
    "\n",
    "    # Rescale the returns to be in percentage points\n",
    "    xs_returns = 100 * xs_returns\n",
    "    total_returns = 100 * total_returns\n",
    "\n",
    "    # Report the statistics\n",
    "    print(f'Performance Statistics for {txt}')\n",
    "    arithm_avg_total_return = annualization_factor * np.mean(total_returns)\n",
    "    arithm_avg_xs_return = annualization_factor * np.mean(xs_returns)\n",
    "    std_xs_returns = np.sqrt(annualization_factor) * np.std(xs_returns, ddof=1)\n",
    "    sharpe_arithmetic = arithm_avg_xs_return / std_xs_returns\n",
    "    print(f'ArithmAvgTotalReturn: {arithm_avg_total_return}')\n",
    "    print(f'ArithmAvgXsReturn: {arithm_avg_xs_return}')\n",
    "    print(f'StdXsReturns: {std_xs_returns}')\n",
    "    print(f'SharpeArithmetic: {sharpe_arithmetic}')\n",
    "    print(f'GeomAvgTotalReturn: {geom_avg_total_return}')\n",
    "    print(f'GeomAvgXsReturn: {geom_avg_xs_return}')\n",
    "    sharpe_geometric = geom_avg_xs_return / std_xs_returns\n",
    "    print(f'SharpeGeometric: {sharpe_geometric}')\n",
    "    print(f'MinXsReturn: {np.min(xs_returns, axis=0)}')\n",
    "    print(f'MaxXsReturn: {np.max(xs_returns, axis=0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmp_Sort(sort_variable, n_longs, n_shorts, long_high_values=1, equal_weights_ls=False):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        sort_variable_sorted = sort_variable  # For long high values, sort descending\n",
    "    else:\n",
    "        sort_variable_sorted = -sort_variable   # For long low values, sort ascending\n",
    "    non_nan_assets = ~np.isnan(sort_variable_sorted)\n",
    "    non_nan_count = np.count_nonzero(non_nan_assets)\n",
    "    \n",
    "    # Check if n_shorts is zero\n",
    "    if n_shorts == 0:\n",
    "        if non_nan_count < n_longs:\n",
    "            n_longs = non_nan_count\n",
    "        tmp_long = list(sort_variable_sorted)\n",
    "        tmp_long = [-10000000 if pd.isna(x) else x for x in tmp_long]\n",
    "        list_of_longs = np.argsort(tmp_long)[-n_longs:]\n",
    "        \n",
    "        weights = np.zeros(len(sort_variable))\n",
    "        weights[list_of_longs] = 1 / n_longs\n",
    "        return weights\n",
    "\n",
    "    # If n_shorts is not zero, handle normally\n",
    "    if non_nan_count < n_longs:\n",
    "        n_longs = non_nan_count\n",
    "        n_shorts = 0\n",
    "    elif n_shorts > 0 and non_nan_count < n_longs + n_shorts:\n",
    "        n_shorts = non_nan_count - n_longs\n",
    "        \n",
    "    if equal_weights_ls == True:\n",
    "        n_shorts = non_nan_count // 2\n",
    "        n_longs = non_nan_count // 2\n",
    "        \n",
    "    \n",
    "\n",
    "    tmp_long = list(sort_variable_sorted)\n",
    "    tmp_long = [-10000000 if pd.isna(x) else x for x in tmp_long]\n",
    "    list_of_longs = np.argsort(tmp_long)[-n_longs:]\n",
    "        \n",
    "    tmp_short = list(sort_variable_sorted)\n",
    "    tmp_short = [100000000 if pd.isna(x) else x for x in tmp_short]\n",
    "    list_of_shorts = np.argsort(tmp_short)[:n_shorts]\n",
    "    \n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent infl – the average of the headline and core annual CPI inflation rate\n",
    "--> we don't have headline inflation\n",
    "\n",
    "\n",
    "Effective target infl - The effective inflation target is the mean of the target range announced or implied by the authorities plus an adjusted for past “target misses”, which is the last 3 years’ average gap between actual inflation and the target means\n",
    "--> we don't have target rates for all countries --> use 2.5 as target rate\n",
    "\n",
    "Formula: (1/n)*recent infl + ((n-1)/n)*effective target infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e12819c2dedb>:35: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.04\n",
      "<ipython-input-9-e12819c2dedb>:26: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-9-e12819c2dedb>:11: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-9-e12819c2dedb>:24: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.033\n",
      "<ipython-input-9-e12819c2dedb>:9: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.025\n",
      "<ipython-input-9-e12819c2dedb>:13: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-9-e12819c2dedb>:33: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.01\n",
      "<ipython-input-9-e12819c2dedb>:31: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-9-e12819c2dedb>:17: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-9-e12819c2dedb>:15: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-9-e12819c2dedb>:22: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n"
     ]
    }
   ],
   "source": [
    "# first we will take the difference between the effective target (mean) inflation and the actual inflation\n",
    "\n",
    "cpiheadline = Inflation.copy()\n",
    "\n",
    "eff_target_diff = pd.DataFrame(columns = cpiheadline.columns, index = cpiheadline.index)\n",
    "\n",
    "for i in eff_target_diff.columns:\n",
    "    if i == \"Australia\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.025\n",
    "    elif i == \"Canada\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"China\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Germany\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"France\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"UK\":\n",
    "        eff_target_diff.loc[:\"2003-11-28\",i] = cpiheadline.loc[:\"2003-11-28\",i] - 0.025\n",
    "        eff_target_diff.loc[\"2003-12-31\":,i] = cpiheadline.loc[\"2003-12-31\":,i] - 0.02\n",
    "    elif i == \"Italy\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Japan\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.033\n",
    "    elif i == \"Singapore\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"USA\":\n",
    "        eff_target_diff.loc[:\"2011-12-31\",i] = cpiheadline.loc[:\"2011-12-31\",i] - 0.0185\n",
    "        eff_target_diff.loc[\"2012-01-31\":,i] = cpiheadline.loc[\"2012-01-31\":,i] - 0.02\n",
    "    elif i == \"Spain\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Switzerland\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.01\n",
    "    elif i == \"India\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.012722222222222225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(eff_target_diff.loc[:\"2002-11-30\", \"Singapore\"])\n",
    "#np.nanmean(eff_target_diff.loc[\"2020-04-30\":, \"Singapore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-653395cf36f9>:15: RuntimeWarning: Mean of empty slice\n",
      "  inflation = np.nanmean(eff_target_diff.iloc[runner-36:runner, j], dtype=float)\n"
     ]
    }
   ],
   "source": [
    "# create the rolling 3-year average of the core inflation\n",
    "\n",
    "# first I have to set up an empty dictionary to store the rolling averages\n",
    "cpiheadline_avg = {}\n",
    "for i in cpiheadline.columns:\n",
    "    cpiheadline_avg[i] = []\n",
    "\n",
    "# next up we iterate over the cpicore data to get the index and safe them in the dictionary\n",
    "runner = len(cpiheadline.index)\n",
    "for i in cpiheadline.index:\n",
    "    if runner == 35:\n",
    "        break\n",
    "    \n",
    "    for j,k in enumerate(cpiheadline.columns):\n",
    "        inflation = np.nanmean(eff_target_diff.iloc[runner-36:runner, j], dtype=float)\n",
    "        cpiheadline_avg[k].insert(0, inflation)\n",
    "    runner -= 1\n",
    "    \n",
    "#cpiheadline_avg\n",
    "cpiheadline_avg_trimmed = pd.DataFrame(cpiheadline_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>India</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Canada</th>\n",
       "      <th>USA</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Australia</th>\n",
       "      <th>China</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>UK</th>\n",
       "      <th>Spain</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Italy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012722</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>-0.040861</td>\n",
       "      <td>0.013686</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.003778</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.040667</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>-0.019139</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>-0.014028</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.003833</td>\n",
       "      <td>0.005778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013278</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>-0.019139</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>-0.040444</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>-0.018917</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>-0.004111</td>\n",
       "      <td>0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>-0.040361</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>-0.018806</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>0.006194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.002639</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.008917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.021597</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>-0.025722</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.012083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.021144</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>-0.024833</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.015167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.020847</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>0.018556</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.017806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.020808</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>-0.023028</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.026306</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.020333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        India  Singapore    Canada       USA     Japan  Australia     China  \\\n",
       "0         NaN  -0.012722  0.004139  0.007306 -0.040861   0.013686 -0.018914   \n",
       "1         NaN  -0.013000  0.004722  0.007167 -0.040667   0.013500 -0.019139   \n",
       "2         NaN  -0.013278  0.005083  0.007083 -0.040500   0.013833 -0.019139   \n",
       "3         NaN  -0.013444  0.005694  0.006917 -0.040444   0.014167 -0.018917   \n",
       "4         NaN  -0.013694  0.006222  0.006694 -0.040361   0.014500 -0.018806   \n",
       "..        ...        ...       ...       ...       ...        ...       ...   \n",
       "240  0.021503   0.004167  0.014000  0.023944 -0.026639   0.002667 -0.000500   \n",
       "241  0.021597   0.005861  0.015278  0.025333 -0.025722   0.004111 -0.001306   \n",
       "242  0.021144   0.007444  0.016417  0.026500 -0.024833   0.005639 -0.002056   \n",
       "243  0.020847   0.009056  0.017389  0.027583 -0.023833   0.007167 -0.002972   \n",
       "244  0.020808   0.010722  0.018222  0.028611 -0.023028   0.008722 -0.004139   \n",
       "\n",
       "     Switzerland        UK     Spain    France   Germany     Italy  \n",
       "0       0.001194 -0.014194  0.014091 -0.003139 -0.003778  0.005556  \n",
       "1       0.000972 -0.014028  0.014500 -0.002778 -0.003833  0.005778  \n",
       "2       0.000750 -0.013889  0.014923 -0.002500 -0.004000  0.006000  \n",
       "3       0.000528 -0.013694  0.015071 -0.002389 -0.004111  0.006139  \n",
       "4       0.000361 -0.013444  0.015267 -0.002056 -0.004167  0.006194  \n",
       "..           ...       ...       ...       ...       ...       ...  \n",
       "240    -0.002639  0.016472  0.014083  0.001833  0.013972  0.008917  \n",
       "241    -0.001778  0.019028  0.015861  0.003278  0.016444  0.012083  \n",
       "242    -0.001056  0.021583  0.017222  0.004528  0.018417  0.015167  \n",
       "243    -0.000194  0.023889  0.018556  0.005778  0.020361  0.017806  \n",
       "244     0.000778  0.026306  0.020028  0.007139  0.022306  0.020333  \n",
       "\n",
       "[245 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpiheadline_avg_trimmed # until here I checked several times whether it is correct and it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-90c02453a451>:21: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  formula_values.iloc[:,j+i*5] = (1/m)*cpiheadline_trimmed[k] +((m-1)/m)*cpiheadline_avg_trimmed[k]\n"
     ]
    }
   ],
   "source": [
    "# now we calculate the value formula:\n",
    "# (1/n)*recent inflation + ((n-1)/n)*effective target inflation for the years: 2, 5, 10, 20, 30\n",
    "\n",
    "# first we need to align the dataframes \n",
    "cpiheadline_trimmed = cpiheadline[35:]\n",
    "cpiheadline_avg_trimmed.set_index(cpiheadline_trimmed.index, inplace = True)\n",
    "\n",
    "# second we create an empty dictionary to fill with the calculations\n",
    "formula_values = {}\n",
    "x = 0\n",
    "for i in cpiheadline_trimmed.columns:\n",
    "    x += 1\n",
    "    for j in [2,5,10,20,30]:\n",
    "        formula_values[f\"{i},{j}\"] = []\n",
    "formula_values = pd.DataFrame(columns = formula_values.keys(), index = cpiheadline_trimmed.index)\n",
    "\n",
    "\n",
    "# now that we have the empty dictionary to fill, we start with caluclating the inflation expectation\n",
    "for i,k in enumerate (cpiheadline_trimmed.columns):\n",
    "    for j,m in enumerate([2,5,10,20,30]):\n",
    "        formula_values.iloc[:,j+i*5] = (1/m)*cpiheadline_trimmed[k] +((m-1)/m)*cpiheadline_avg_trimmed[k]\n",
    "        \n",
    "#formula_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to align the NA's from the ETF with the NA's from the Yields such that we don't get a weight for a date that\n",
    "# we don't have return data for\n",
    "\n",
    "Yield_na = Yield_long.copy()\n",
    "ETF_na = ETF.pct_change().isna()\n",
    "ETF_na\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i,k in enumerate(Yield_na.columns):\n",
    "    if counter == 5:\n",
    "        counter = 0\n",
    "        runner += 1\n",
    "    tmp = ETF_na.iloc[:,runner]\n",
    "    Yield_na.iloc[tmp,i] = np.nan\n",
    "    counter +=1\n",
    "Yield_na\n",
    "\n",
    "\n",
    "# now we have the issue that the Yield_clean data and the Inflation_clean data doesn't have the same sequence of countries\n",
    "# to avoid this we resort the Yield_clean data to fit the Inflation_clean data\n",
    "\n",
    "clean_names = [\"Germany\", \"France\",\"Spain\",\"Italy\",\"United Kingdom\", \"Switzerland\", \"China\", \"Australia\", \"Japan\", \"USA\", \"Canada\", \"Singapore\", \"India\"]\n",
    "\n",
    "# we split the dataframe into the different countries...\n",
    "Germany = Yield_na.iloc[:,:5]\n",
    "France = Yield_na.iloc[:,5:10]\n",
    "Spain = Yield_na.iloc[:,10:15]\n",
    "Italy = Yield_na.iloc[:,15:20]\n",
    "UK = Yield_na.iloc[:,20:25]\n",
    "Switzerland = Yield_na.iloc[:,25:30]\n",
    "China = Yield_na.iloc[:,30:35]\n",
    "Australia = Yield_na.iloc[:,35:40]\n",
    "Japan = Yield_na.iloc[:,40:45]\n",
    "USA = Yield_na.iloc[:,45:50]\n",
    "Canada = Yield_na.iloc[:,50:55]\n",
    "Singapore = Yield_na.iloc[:,55:60]\n",
    "India = Yield_na.iloc[:,60:]\n",
    "\n",
    "# ... and fusion them together to have the same order as the Inflation data (plus dividing by 100 to have same level as Inflation)\n",
    "Yields_aligned = [India, Singapore, Canada, USA, Japan, Australia, China, Switzerland, UK, Spain, France, Germany, Italy]\n",
    "Yields_aligned = pd.concat(Yields_aligned, axis=1)\n",
    "Yields_aligned = Yields_aligned /100\n",
    "#Yields_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a next step we adjust the yield data to have the same lookback as the other data\n",
    "\n",
    "Yield_trimmed = Yields_aligned[35:]\n",
    "\n",
    "Real_yield = pd.DataFrame(0, columns = formula_values.columns, index = formula_values.index)\n",
    "\n",
    "# now we take the difference between yield etf and inflation\n",
    "for i,k in enumerate(formula_values.columns):\n",
    "    for j,l in enumerate(formula_values.index):\n",
    "        Real_yield.iloc[j,i] = Yield_trimmed.iloc[j,i] - formula_values.iloc[j,i]\n",
    "#Real_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-1ebfb3f6f625>:7: RuntimeWarning: Mean of empty slice\n",
      "  temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n",
      "<ipython-input-16-1ebfb3f6f625>:8: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  Real_yield_avg.iloc[:,runner] = temp.values\n",
      "<ipython-input-16-1ebfb3f6f625>:7: RuntimeWarning: Mean of empty slice\n",
      "  temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n"
     ]
    }
   ],
   "source": [
    "# in a final step we will average over the duration of the countries to get one average for each country\n",
    "\n",
    "Real_yield_avg = pd.DataFrame(columns = cpiheadline_avg_trimmed.columns, index = Real_yield.index)\n",
    "\n",
    "runner = 0\n",
    "for i in range(0, len(Yields_aligned.columns)-1, 5):\n",
    "    temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n",
    "    Real_yield_avg.iloc[:,runner] = temp.values\n",
    "    runner +=1\n",
    "    \n",
    "#Real_yield_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Monthly Returns out of ETF Prices\n",
    "ETF_price = ETF.copy()\n",
    "ETF_returns = ETF_price.pct_change()\n",
    "ETF_ret = ETF_returns.tail(-1)\n",
    "rf = Yield_short.iloc[:,0] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Weights for Momentum\n",
    "\n",
    "# Prep Work\n",
    "nAssets = len(ETF_price.columns) # 13 Countries\n",
    "nMonths = len(ETF_price) # 280 Months of prices (31.12.1999 - 31.03.2023)\n",
    "lookbackStart = 12\n",
    "lookbackEnd = 1\n",
    "firstMonth = lookbackStart + 1 # we can only start computing weights in 13.month bc we have 12 months lookback \n",
    "nLongs = 5\n",
    "nShorts = 5\n",
    "momLongWeights = pd.DataFrame(np.zeros((nMonths, nAssets)))\n",
    "momLSWeights = pd.DataFrame(np.zeros((nMonths, nAssets)))\n",
    "long_weight = np.divide(1,nLongs)\n",
    "short_weight = np.divide(1,nShorts)*(-1)\n",
    "\n",
    " # Loop to get the Long weights and the Long/Short Weights\n",
    "for month in range(firstMonth, nMonths):\n",
    "     pastReturns = pd.DataFrame(np.divide(ETF_price.iloc[month - lookbackEnd, :], ETF_price.iloc[month - lookbackStart, :]) - 1)\n",
    "     highReturns = pastReturns.nlargest(nLongs,columns=pastReturns.columns)\n",
    "     lowReturns = pastReturns.nsmallest(nShorts,columns=pastReturns.columns)\n",
    "     low_index = lowReturns.index\n",
    "     high_index = highReturns.index\n",
    "     pRet_index = pastReturns.index\n",
    "\n",
    "     high_index_numbers = pRet_index.get_indexer(high_index)\n",
    "     low_index_numbers = pRet_index.get_indexer(low_index)\n",
    "     # Long Weights only\n",
    "     momLongWeights.iloc[month,high_index_numbers] = long_weight\n",
    "     # Long/Short Weights only\n",
    "     momLSWeights.iloc[month,high_index_numbers] = long_weight\n",
    "     momLSWeights.iloc[month,low_index_numbers] = short_weight\n",
    "\n",
    "# Set Index and Column Names again\n",
    "momLongWeights = momLongWeights.set_index(ETF_price.index).copy()\n",
    "momLongWeights.columns = ETF_price.columns\n",
    "momLSWeights = momLSWeights.set_index(ETF_price.index).copy()\n",
    "momLSWeights.columns = ETF_price.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleanup -> Returns in sync with weights!\n",
    "momLongWeights_cut = momLongWeights.iloc[firstMonth:, :] # cut out first 13 months -> first row now is weight calculated at 31.01.2000; keep extra row at end for Turnover\n",
    "momLSWeights_cut = momLSWeights.iloc[firstMonth:, :] # cut out first 13 months -> first row now is weight calculated at 31.01.2000; keep extra row at end for Turnover\n",
    "ETF_ret_cut = ETF_ret.iloc[firstMonth :, :] #we need Returns from 28.02.2000\n",
    "FX_ret_cut = FX_ret.iloc[firstMonth+12:-1,:]\n",
    "rf_cut_mom = rf.iloc[firstMonth+1:]\n",
    "dates4Fig = ETF_ret_cut.index\n",
    "nMonths_actual = nMonths - (firstMonth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX_ret_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-71f642dfb2bc>:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  LongAssetRet = np.sum(np.multiply(ETF_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)\n",
      "<ipython-input-23-71f642dfb2bc>:5: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  LongFXRet = np.sum(np.multiply(FX_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)\n",
      "<ipython-input-23-71f642dfb2bc>:8: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  LSAssetRet = np.sum(np.multiply(ETF_ret_cut, momLSWeights_cut.iloc[ : -1, :]), axis=1) + rf_cut_mom\n",
      "<ipython-input-23-71f642dfb2bc>:9: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  LSFXRet = np.sum(np.multiply(FX_ret_cut, momLSWeights_cut.iloc[ : -1, :]), axis=1) + rf_cut_mom\n"
     ]
    }
   ],
   "source": [
    "# Calculate Strategy Returns with No Transaction Cost\n",
    "# note we only take weights rows until end -1 bc we left one to much in\n",
    "# Long Strategy\n",
    "LongAssetRet = np.sum(np.multiply(ETF_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)\n",
    "LongFXRet = np.sum(np.multiply(FX_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)\n",
    "LongStratRet = np.add(LongAssetRet, LongFXRet)\n",
    "# Long/Short Strategy\n",
    "LSAssetRet = np.sum(np.multiply(ETF_ret_cut, momLSWeights_cut.iloc[ : -1, :]), axis=1) + rf_cut_mom\n",
    "LSFXRet = np.sum(np.multiply(FX_ret_cut, momLSWeights_cut.iloc[ : -1, :]), axis=1) + rf_cut_mom\n",
    "LSStratRet = np.add(LSAssetRet, LongFXRet)\n",
    "# Combined into 1 Dataframe\n",
    "stratReturnsNoTC = pd.concat([LongStratRet,LSStratRet], axis=1)\n",
    "stratReturnsNoTC = stratReturnsNoTC.set_axis(['Long_Mom_NoTC','LS_Mom_NoTC'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turnover Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Compute Turnover for Momentum\n",
    "# turnover_mom = np.zeros((nMonths_actual, 2))\n",
    "# stratReturnsTC = np.zeros((nMonths_actual, 2))\n",
    "\n",
    "# for month in range(0, nMonths_actual):\n",
    "#     currentRf = rf_cut_mom.iloc[month]\n",
    "#     currentRet = ETF_ret_cut.iloc[month, :]\n",
    "#     turnover_mom[month, 0] = computeTurnover(momLongWeights_cut.iloc[month, :], momLongWeights_cut.iloc[month + 1, :], currentRet, currentRf)[0]\n",
    "#     turnover_mom[month, 1] = computeTurnover(momLSWeights_cut.iloc[month, :], momLSWeights_cut.iloc[month + 1, :], currentRet, currentRf)[0]\n",
    "#     #print(\"Current value of month is:\", month)\n",
    "\n",
    "# avgTurnover_Longmom = np.mean(turnover_mom[:,0])\n",
    "# avgTurnover_LSmom = np.mean(turnover_mom[:,1])\n",
    "# print(\"Avg Turnover (monthly) of LongMom is:\", avgTurnover_Longmom)\n",
    "# print(\"Avg Turnover (monthly) of LSMom is:\", avgTurnover_LSmom)\n",
    "\n",
    "# stratReturnsTC = stratReturnsNoTC - (tCost * turnover_mom)\n",
    "# stratReturnsTC = stratReturnsTC.set_axis(['Long_Mom_TC','LS_Mom_TC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratReturnsNoTC\n",
    "#stratReturnsTC\n",
    "LongStratRet\n",
    "#ETF_ret_cut\n",
    "#momLongWeights_cut\n",
    "#momLongWeights_cut.iloc[ : -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Turnover (monthly) of LongMom is: 0.3054318751129565\n",
      "Avg Turnover (monthly) of LSMom is: 0.6260178165041754\n"
     ]
    }
   ],
   "source": [
    "## Compute Turnover for Momentum (again)\n",
    "turnover_mom = np.zeros((nMonths_actual, 2))\n",
    "#stratReturnsTC = np.zeros((nMonths_actual, 2))\n",
    "\n",
    "for month in range(0, nMonths_actual):\n",
    "    currentRf = rf_cut_mom.iloc[month]\n",
    "    currentRet = ETF_ret_cut.iloc[month, :]\n",
    "    turnover_mom[month, 0] = computeTurnover(momLongWeights_cut.iloc[month, :], momLongWeights_cut.iloc[month + 1, :], currentRet, currentRf)[0]\n",
    "    turnover_mom[month, 1] = computeTurnover(momLSWeights_cut.iloc[month, :], momLSWeights_cut.iloc[month + 1, :], currentRet, currentRf)[0]\n",
    "    #print(\"Current value of month is:\", month)\n",
    "\n",
    "x = np.insert(turnover_mom, 0, [1,0.4], axis = 0)\n",
    "turnover_mom = x.copy()\n",
    "    \n",
    "avgTurnover_Longmom = np.mean(turnover_mom[:,0])\n",
    "avgTurnover_LSmom = np.mean(turnover_mom[:,1])\n",
    "print(\"Avg Turnover (monthly) of LongMom is:\", avgTurnover_Longmom)\n",
    "print(\"Avg Turnover (monthly) of LSMom is:\", avgTurnover_LSmom)\n",
    "\n",
    "stratReturnsTC = stratReturnsNoTC - (tCost * turnover_mom)\n",
    "stratReturnsTC = stratReturnsTC.set_axis(['Long_Mom_TC','LS_Mom_TC'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-426934d8fae2>:8: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  allXsReturns_mom = np.subtract(allTotalReturns_mom , rf_cut_mom_matrix)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (267, 4): given (266, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-426934d8fae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# All Excess Returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrf_cut_mom_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrf_cut_mom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_cut_mom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_cut_mom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_cut_mom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mallXsReturns_mom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallTotalReturns_mom\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrf_cut_mom_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msummarize_performance2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallXsReturns_mom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_cut_mom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallXsReturns_mom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannualizationFactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Long_Mom_NoTC, LS_Mom_NoTC, Long_Mom_TC, LS_Mom_TC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2112\u001b[0m     ):\n\u001b[1;32m-> 2113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# for backwards compatibility check and potentially fallback for non-aligned frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_fallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m_maybe_fallback\u001b[1;34m(ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;31m# call the ufunc on those transformed inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;31m# signal that we didn't fallback / execute the ufunc yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2112\u001b[0m     ):\n\u001b[1;32m-> 2113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_dispatch_ufunc_to_dunder_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__sub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rsub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7579\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_prepare_scalar_for_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7581\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7583\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36malign_method_FRAME\u001b[1;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    265\u001b[0m                     \u001b[1;34m\"Unable to coerce to DataFrame, shape \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                     \u001b[1;34mf\"must be {left.shape}: given {right.shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (267, 4): given (266, 4)"
     ]
    }
   ],
   "source": [
    "# Get Summary Statistics\n",
    "# Prep Work\n",
    "annualizationFactor = 12\n",
    "# All Total Returns\n",
    "allTotalReturns_mom = pd.concat([stratReturnsNoTC,stratReturnsTC], axis=1)\n",
    "# All Excess Returns\n",
    "rf_cut_mom_matrix = pd.concat([rf_cut_mom,rf_cut_mom,rf_cut_mom,rf_cut_mom], axis=1)\n",
    "allXsReturns_mom = np.subtract(allTotalReturns_mom , rf_cut_mom_matrix)\n",
    "\n",
    "summarize_performance2(allXsReturns_mom, rf_cut_mom, allXsReturns_mom.iloc[:,0], annualizationFactor, 'Long_Mom_NoTC, LS_Mom_NoTC, Long_Mom_TC, LS_Mom_TC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (266,) and (267,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-674559531bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstrategyNAV_mom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mallTotalReturns_mom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create the line plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates4Fig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategyNAV_mom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LS_Mom_NoTC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashdot'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates4Fig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategyNAV_mom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LS_Mom_TC'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates4Fig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategyNAV_mom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Long_Mom_NoTC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashdot'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (266,) and (267,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Strategy Performances\n",
    "strategyNAV_mom = np.cumprod(1 + allTotalReturns_mom)\n",
    "# Create the line plot\n",
    "plt.plot(dates4Fig, strategyNAV_mom.iloc[:,1], label='LS_Mom_NoTC', linestyle='dashdot',color=\"red\")\n",
    "plt.plot(dates4Fig, strategyNAV_mom.iloc[:,3], label='LS_Mom_TC',color=\"red\")\n",
    "plt.plot(dates4Fig, strategyNAV_mom.iloc[:,0], label='Long_Mom_NoTC', linestyle='dashdot',color=\"blue\")\n",
    "plt.plot(dates4Fig, strategyNAV_mom.iloc[:,2], label='Long_Mom_TC',color=\"blue\")\n",
    "\n",
    "# Set the x and y axis labels and legend\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-fb6f15460685>:14: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  Carry_3m.iloc[:,i] = Yield_na.iloc[:,i] - Yield_short.iloc[:,runner]\n",
      "<ipython-input-18-fb6f15460685>:18: RuntimeWarning: Mean of empty slice\n",
      "  avg_Carry_3m.iloc[:,i] = np.nanmean([Carry_3m.iloc[:,i*5], Carry_3m.iloc[:,i*5+1], Carry_3m.iloc[:,i*5+2], Carry_3m.iloc[:,i*5+3], Carry_3m.iloc[:,i*5+4]], axis = 0)\n"
     ]
    }
   ],
   "source": [
    "# for carry we will now calculate the differences between the long-term yields (2,5,10,20,30) and short-term yields (1M, 3M)\n",
    "# we will create a dataframe for the 1M and the 3M\n",
    "# I take the Yield_na for the calculation to get the same NA's as the ETF has\n",
    "\n",
    "Carry_3m = pd.DataFrame(columns = Yield_long.columns, index = Yield_long.index)\n",
    "avg_Carry_3m = pd.DataFrame(0, columns = Yield_short.columns, index = Yield_short.index)\n",
    "\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i in range(0,len(Yield_long.columns)):\n",
    "    if counter == 5:\n",
    "        runner += 1\n",
    "        counter = 0\n",
    "    Carry_3m.iloc[:,i] = Yield_na.iloc[:,i] - Yield_short.iloc[:,runner]\n",
    "    counter += 1\n",
    "    \n",
    "for i in range(0,len(Yield_short.columns)):\n",
    "    avg_Carry_3m.iloc[:,i] = np.nanmean([Carry_3m.iloc[:,i*5], Carry_3m.iloc[:,i*5+1], Carry_3m.iloc[:,i*5+2], Carry_3m.iloc[:,i*5+3], Carry_3m.iloc[:,i*5+4]], axis = 0)\n",
    "\n",
    "avg_Carry_3m = avg_Carry_3m / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value\n",
    "weights = pd.DataFrame(columns = Real_yield_avg.columns, index = Real_yield_avg.index)\n",
    "\n",
    "for i,k in enumerate(Real_yield_avg.index):\n",
    "    temp = pmp_Sort(Real_yield_avg.iloc[i,:], 5,5)\n",
    "    weights.iloc[i,:] = temp\n",
    "    \n",
    "# now we need to align the columns of weights to columns of returns\n",
    "ETF_value = ETF_returns.copy()\n",
    "ETF_value.rename(columns = {\"Swiss comb\": \"Switzerland\"}, inplace=True)\n",
    "\n",
    "Value_weights = pd.DataFrame(0,columns = ETF_value.columns, index = ETF_value.index)\n",
    "weights.set_index(ETF_value.index[35:], inplace=True)\n",
    "for i in ETF_value.columns:\n",
    "    Value_weights.loc[\"2002-11-29\":,i] = weights.loc[:,i]\n",
    "    \n",
    "    \n",
    "    \n",
    "# Value Long only\n",
    "weights = pd.DataFrame(columns = Real_yield_avg.columns, index = Real_yield_avg.index)\n",
    "\n",
    "for i,k in enumerate(Real_yield_avg.index):\n",
    "    temp = pmp_Sort(Real_yield_avg.iloc[i,:], 5,0)\n",
    "    weights.iloc[i,:] = temp\n",
    "    \n",
    "\n",
    "# now we need to align the columns of weights to columns of returns\n",
    "ETF_value = ETF_returns.copy()\n",
    "ETF_value.rename(columns = {\"Swiss comb\": \"Switzerland\"}, inplace=True)\n",
    "\n",
    "Value_weights_LO = pd.DataFrame(0,columns = ETF_value.columns, index = ETF_value.index)\n",
    "weights.set_index(ETF_value.index[35:], inplace=True)\n",
    "for i in ETF_value.columns:\n",
    "    Value_weights_LO.loc[\"2002-11-29\":,i] = weights.loc[:,i]\n",
    "\n",
    "# print(Value_weights)\n",
    "# print(Value_weights_LO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum\n",
    "Momentum_weights = momLSWeights.copy()\n",
    "Momentum_weights_LO = momLongWeights.copy()\n",
    "Momentum_weights.rename(columns = {\"Swiss comb\": \"Switzerland\"}, inplace = True)\n",
    "Momentum_weights_LO.rename(columns = {\"Swiss comb\": \"Switzerland\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry\n",
    "Carry_weights = pd.DataFrame(columns = avg_Carry_3m.columns, index = avg_Carry_3m.index)\n",
    "\n",
    "for i,k in enumerate(avg_Carry_3m.index):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    temp = pmp_Sort(avg_Carry_3m.iloc[i,:], 5, 5)\n",
    "    Carry_weights.iloc[i,:] = temp\n",
    "\n",
    "    \n",
    "    \n",
    "# Carry Long only\n",
    "Carry_weights_LO = pd.DataFrame(columns = avg_Carry_3m.columns, index = avg_Carry_3m.index)\n",
    "\n",
    "for i,k in enumerate(avg_Carry_3m.index):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    temp = pmp_Sort(avg_Carry_3m.iloc[i,:], 5, 0)\n",
    "    Carry_weights_LO.iloc[i,:] = temp\n",
    "\n",
    "# print(Carry_weights)\n",
    "# print(Carry_weights_LO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-690617cb181a>:36: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  p = 1/pos_sum\n",
      "<ipython-input-77-690617cb181a>:37: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  n = -1/neg_sum\n",
      "<ipython-input-77-690617cb181a>:56: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  p = 1/pos_sum\n"
     ]
    }
   ],
   "source": [
    "# in the following we will combine the weight matrices that we've gathered sofar into two distinct weight matrices for the PF\n",
    "# the PF_weight_score will be a number between -3 and 3 indicating the signals suggesting the country\n",
    "# the PF_weight will just be the sum of the weights\n",
    "\n",
    "PF_weights = Value_weights + Carry_weights + Momentum_weights\n",
    "PF_weights_LO = Value_weights_LO + Carry_weights_LO + Momentum_weights_LO\n",
    "\n",
    "# now we will create the scored weights\n",
    "PF_score = pd.DataFrame(0, columns = Value_weights.columns, index = Value_weights.index)\n",
    "PF_weights_score = pd.DataFrame(0.0, columns = Value_weights.columns, index = Value_weights.index)\n",
    "PF_score_LO = pd.DataFrame(0, columns = Value_weights.columns, index = Value_weights.index)\n",
    "PF_weights_score_LO = pd.DataFrame(0.0, columns = Value_weights.columns, index = Value_weights.index)\n",
    "\n",
    "# Long short\n",
    "\n",
    "value_pos = Value_weights > 0\n",
    "value_neg = Value_weights < 0\n",
    "carry_pos = Carry_weights > 0\n",
    "carry_neg = Carry_weights < 0\n",
    "mom_pos = Momentum_weights > 0\n",
    "mom_neg = Momentum_weights < 0\n",
    "\n",
    "PF_score[value_pos] = 1\n",
    "PF_score[value_neg] = -1\n",
    "PF_score[carry_pos] += 1\n",
    "PF_score[carry_neg] -= 1\n",
    "PF_score[mom_pos] += 1\n",
    "PF_score[mom_neg] -= 1\n",
    "\n",
    "# now we will create the weights for the PF_weights_score\n",
    "for i,k in enumerate(PF_score.index):\n",
    "    pos = PF_score.iloc[i,:] > 0\n",
    "    neg = PF_score.iloc[i,:] < 0\n",
    "    pos_sum = pos.sum()\n",
    "    neg_sum = neg.sum()\n",
    "    p = 1/pos_sum\n",
    "    n = -1/neg_sum\n",
    "    PF_weights_score.iloc[i,:][pos] = p\n",
    "    PF_weights_score.iloc[i,:][neg] = n\n",
    "    \n",
    "    \n",
    "# Long only\n",
    "\n",
    "value_pos = Value_weights_LO > 0\n",
    "carry_pos = Carry_weights_LO > 0\n",
    "mom_pos = Momentum_weights_LO > 0\n",
    "\n",
    "PF_score_LO[value_pos] = 1\n",
    "PF_score_LO[carry_pos] += 1\n",
    "PF_score_LO[mom_pos] += 1\n",
    "\n",
    "# now we will create the weights for the PF_weights_score\n",
    "for i,k in enumerate(PF_score_LO.index):\n",
    "    pos = PF_score_LO.iloc[i,:] > 0\n",
    "    pos_sum = pos.sum()\n",
    "    p = 1/pos_sum\n",
    "    PF_weights_score_LO.iloc[i,:][pos] = p\n",
    "\n",
    "    \n",
    "# print(PF_weights_score)\n",
    "# print(PF_weights_score_LO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the weights of the different strategies and the returns of the ETF's we can calculate the returns\n",
    "\n",
    "# Value\n",
    "Value_returns = Value_weights.mul(ETF_returns)\n",
    "Value_returns_LO = Value_weights_LO.mul(ETF_returns)\n",
    "Value_ret_LS = pd.DataFrame(np.nansum(Value_returns, axis = 1), columns = [\"Value LS no TC\"], index = Value_returns.index)\n",
    "Value_ret_LO = pd.DataFrame(np.nansum(Value_returns_LO, axis = 1), columns = [\"Value LO no TC\"], index = Value_returns.index)\n",
    "Value_ret = pd.concat([Value_ret_LS, Value_ret_LO], axis = 1)\n",
    "\n",
    "# Carry\n",
    "Carry_returns = Carry_weights.mul(ETF_returns)\n",
    "Carry_returns_LO = Carry_weights_LO.mul(ETF_returns)\n",
    "Carry_ret_LS = pd.DataFrame(np.nansum(Carry_returns, axis = 1), columns = [\"Carry LS no TC\"], index = Carry_returns.index)\n",
    "Carry_ret_LO = pd.DataFrame(np.nansum(Carry_returns_LO, axis = 1), columns = [\"Carry LO no TC\"], index = Carry_returns.index)\n",
    "Carry_ret = pd.concat([Carry_ret_LS, Carry_ret_LO], axis = 1)\n",
    "\n",
    "# Momentum\n",
    "Momentum_returns = Momentum_weights.mul(ETF_returns)\n",
    "Momentum_returns_LO = Momentum_weights_LO.mul(ETF_returns)\n",
    "Momentum_ret_LS = pd.DataFrame(np.nansum(Momentum_returns, axis = 1), columns = [\"Momentum LS no TC\"], index = Momentum_returns.index)\n",
    "Momentum_ret_LO = pd.DataFrame(np.nansum(Momentum_returns_LO, axis = 1), columns = [\"Momentum LO no TC\"], index = Momentum_returns.index)\n",
    "Momentum_ret = pd.concat([Momentum_ret_LS, Momentum_ret_LO], axis = 1)\n",
    "\n",
    "# PF basic\n",
    "PF_basic_returns = PF_weights.mul(ETF_returns)\n",
    "PF_basic_returns_LO = PF_weights_LO.mul(ETF_returns)\n",
    "PF_ret_LS = pd.DataFrame(np.nansum(PF_basic_returns, axis = 1), columns = [\"PF LS no TC\"], index = PF_basic_returns.index)\n",
    "PF_ret_LO = pd.DataFrame(np.nansum(PF_basic_returns_LO, axis = 1), columns = [\"PF LO no TC\"], index = PF_basic_returns.index)\n",
    "PF_ret = pd.concat([PF_ret_LS, PF_ret_LO], axis = 1)\n",
    "\n",
    "# PF scoring\n",
    "PF_score_returns = PF_weights_score.mul(ETF_returns)\n",
    "PF_score_returns_LO = PF_weights_score_LO.mul(ETF_returns)\n",
    "PF_score_ret_LS = pd.DataFrame(np.nansum(PF_score_returns, axis = 1), columns = [\"Value LS no TC\"], index = PF_score_returns.index)\n",
    "PF_score_ret_LO = pd.DataFrame(np.nansum(PF_score_returns_LO, axis = 1), columns = [\"Value LO no TC\"], index = PF_score_returns.index)\n",
    "PF_score_ret = pd.concat([PF_score_ret_LS, PF_score_ret_LO], axis = 1)\n",
    "\n",
    "\n",
    "# print(Value_returns)\n",
    "# print(Carry_returns)\n",
    "# print(Momentum_returns)\n",
    "# print(PF_basic_returns)\n",
    "# print(PF_score_returns)\n",
    "\n",
    "# print(Value_returns_LO)\n",
    "# print(Carry_returns_LO)\n",
    "# print(Momentum_returns_LO)\n",
    "# print(PF_basic_returns_LO)\n",
    "# print(PF_score_returns_LO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using the ETF_returns, and the respective weights for the calcuclation of the transaction costs\n",
    "# furthermore we need the return of the whole portfolio to calculate the TC\n",
    "\n",
    "# Value\n",
    "\n",
    "Value_ret_cut = Value_ret.iloc[34:,]\n",
    "\n",
    "months_value = 245\n",
    "Value_weights_cut = Value_weights.iloc[35:,:]\n",
    "Value_weights_LO_cut = Value_weights_LO.iloc[35:,:]\n",
    "ETF_value_cut = ETF_returns.iloc[35:,:]\n",
    "rf_value_cut = rf[35:]\n",
    "\n",
    "turnover_value = np.zeros((months_value,2))\n",
    "\n",
    "for month in range(0, months_value-1):\n",
    "    currentRf = rf_value_cut[month]\n",
    "    currentRet = ETF_value_cut.iloc[month,:]\n",
    "    turnover_value[month, 0] = computeTurnover(Value_weights_cut.iloc[month, :], Value_weights_cut.iloc[month+1, :], currentRet, currentRf)[0]\n",
    "    turnover_value[month, 1] = computeTurnover(Value_weights_LO_cut.iloc[month, :], Value_weights_LO_cut.iloc[month+1, :], currentRet, currentRf)[0]\n",
    "\n",
    "x = np.insert(turnover_value, 0, [1,1], axis = 0)\n",
    "turnover_value = x.copy()\n",
    "turnover_value[months_value, :] = [1,1]\n",
    "\n",
    "avgTurnover_LSvalue = np.mean(turnover_value[:,0])\n",
    "avgTurnover_Longvalue = np.mean(turnover_value[:,1])\n",
    "\n",
    "Value_returns_TC = Value_ret_cut - (tCost * turnover_value)\n",
    "Value_returns_TC.rename(columns = {\"Value LS no TC\": \"Value LS TC\", \"Value LO no TC\": \"Value LO TC\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing for carry\n",
    "\n",
    "Carry_ret_cut = Carry_ret.copy()\n",
    "\n",
    "months_value = 279\n",
    "Carry_weights_cut = Carry_weights.iloc[1:,:]\n",
    "Carry_weights_LO_cut = Carry_weights_LO.iloc[1:,:]\n",
    "ETF_value_cut = ETF_returns.iloc[1:,:]\n",
    "rf_value_cut = rf[1:]\n",
    "\n",
    "turnover_value = np.zeros((months_value,2))\n",
    "\n",
    "for month in range(0, months_value-1):\n",
    "    currentRf = rf_value_cut[month]\n",
    "    currentRet = ETF_value_cut.iloc[month,:]\n",
    "    turnover_value[month, 0] = computeTurnover(Carry_weights_cut.iloc[month, :], Carry_weights_cut.iloc[month+1, :], currentRet, currentRf)[0]\n",
    "    turnover_value[month, 1] = computeTurnover(Carry_weights_LO_cut.iloc[month, :], Carry_weights_LO_cut.iloc[month+1, :], currentRet, currentRf)[0]\n",
    "\n",
    "x = np.insert(turnover_value, 0, [1,1], axis = 0)\n",
    "turnover_value = x.copy()\n",
    "turnover_value[months_value] = [1,1]\n",
    "\n",
    "avgTurnover_LScarry = np.mean(turnover_value[:,0])\n",
    "avgTurnover_Longcarry = np.mean(turnover_value[:,1])\n",
    "\n",
    "Carry_returns_TC = Carry_ret_cut - (tCost * turnover_value)\n",
    "Carry_returns_TC.rename(columns = {\"Carry LS no TC\": \"Carry LS TC\", \"Carry LO no TC\": \"Carry LO TC\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Carry_ret_cut)\n",
    "print(Carry_returns_TC)\n",
    "print(Value_ret_cut)\n",
    "print(Value_returns_TC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Currency Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = df[[\"MSCI_EU\"]]\n",
    "benchmark = benchmark.loc[\"1999-12-31 00:00:00\":\"2022-09-30 00:00:00\"]\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_mtl_ret = mtl_ret = benchmark.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "bm_mtl_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare momentum result vs benchmark\n",
    "comparison = pd.DataFrame(bm_mtl_ret)\n",
    "comparison[\"mom_ret\"] = profits\n",
    "comparison.rename(columns={ comparison.columns[0]: \"bench_ret\" }, inplace = True)\n",
    "comparison[\"bench_indexed\"] = comparison[\"bench_ret\"].add(1).cumprod()\n",
    "comparison[\"mom_indexed\"] = comparison[\"mom_ret\"].add(1).cumprod()\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(comparison.index,comparison.mom_indexed, label=\"Momentum\", color=\"red\")\n",
    "ax.plot(comparison.index,comparison.bench_indexed, label=\"MSCI EU\", color=\"blue\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_ylabel('Monthly Returns')\n",
    "ax.set_title(\"Momentum long/short 5 sectors monthly rebalancing vs MSCI EU, indexed 31.12.1999\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa336b74a8cbeead930f17f553be49714fc6c4491fbee50d1179d377ec590ae0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
