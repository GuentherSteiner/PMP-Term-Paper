{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can recall from critisicm regarding this presentation:\n",
    "\n",
    "- did not take the equal weighted as benchmark\n",
    "- use total return indices (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import required Packages ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Seaborn\n",
    "sb.set_style(\"ticks\")\n",
    "sb.mpl.rc(\"figure\", figsize=(16,8))\n",
    "sb.mpl.rc(\"font\", size=14)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "# little function for later\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawdata is direct import from excel\n",
    "\n",
    "# Import of excel data, sheet by sheet\n",
    "xls_ETF = pd.ExcelFile(\"1_Data/Data Clean TM/Data_ETFxIndex_stiched.xlsx\")\n",
    "xls_Inflation = pd.ExcelFile(\"1_Data/Data Clean TM/Data_Inflation.xlsx\")\n",
    "xls_Yield = pd.ExcelFile(\"1_Data/Data Clean TM/Yields_Clean_TM.xlsx\")\n",
    "xls_FX = pd.ExcelFile(\"1_Data/Data Clean TM/Data_FX_spot.xlsx\")\n",
    "\n",
    "ETF_raw = pd.DataFrame(pd.read_excel(xls_ETF))\n",
    "Inflation_raw = pd.DataFrame(pd.read_excel(xls_Inflation, 2))\n",
    "Yield_long_raw = pd.DataFrame(pd.read_excel(xls_Yield, 2))\n",
    "Yield_short_raw = pd.DataFrame(pd.read_excel(xls_Yield, 3))\n",
    "FX_raw = pd.DataFrame(pd.read_excel(xls_FX, 4))\n",
    "\n",
    "# keep a safe copy of the rawdata to compare the changes\n",
    "ETF = ETF_raw.copy()\n",
    "Inflation = Inflation_raw.copy()\n",
    "Yield_long = Yield_long_raw.copy()\n",
    "Yield_short = Yield_short_raw.copy()\n",
    "FX = FX_raw.copy()\n",
    "\n",
    "# Set date as index\n",
    "ETF.set_index(\"Datum\", inplace=True)\n",
    "Inflation.set_index(\"Datum\", inplace=True)\n",
    "Yield_long.set_index(\"Datum\", inplace=True)\n",
    "Yield_short.set_index(\"Datum\", inplace=True)\n",
    "FX.set_index(\"Dates\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns in which only text is and safe them separately --> ONLY RUN ONCE\n",
    "# ETF_text = ETF.iloc[0,:]\n",
    "# Yield_text = Yield.iloc[0,:]\n",
    "# Yield_short_text = Yield_short.iloc[0,:]\n",
    "# cpicore_text = cpicore.iloc[0:1,:]\n",
    "# ETF.drop([0], inplace = True)\n",
    "# Yield.drop([0], inplace = True)\n",
    "# Yield_short.drop([0], inplace = True)\n",
    "# cpicore.drop([0,1], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First return calculations for further calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the FX return and the ETF return\n",
    "FX_return = FX.pct_change()\n",
    "ETF_return = ETF.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent infl – the average of the headline and core annual CPI inflation rate\n",
    "--> we don't have headline inflation\n",
    "\n",
    "\n",
    "Effective target infl - The effective inflation target is the mean of the target range announced or implied by the authorities plus an adjusted for past “target misses”, which is the last 3 years’ average gap between actual inflation and the target means\n",
    "--> we don't have target rates for all countries --> use 2.5 as target rate\n",
    "\n",
    "Formula: (1/n)*recent infl + ((n-1)/n)*effective target infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-e12819c2dedb>:35: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.04\n",
      "<ipython-input-5-e12819c2dedb>:26: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-5-e12819c2dedb>:11: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-5-e12819c2dedb>:24: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.033\n",
      "<ipython-input-5-e12819c2dedb>:9: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.025\n",
      "<ipython-input-5-e12819c2dedb>:13: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-5-e12819c2dedb>:33: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.01\n",
      "<ipython-input-5-e12819c2dedb>:31: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-5-e12819c2dedb>:17: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-5-e12819c2dedb>:15: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
      "<ipython-input-5-e12819c2dedb>:22: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n"
     ]
    }
   ],
   "source": [
    "# first we will take the difference between the effective target (mean) inflation and the actual inflation\n",
    "\n",
    "cpiheadline = Inflation.copy()\n",
    "\n",
    "eff_target_diff = pd.DataFrame(columns = cpiheadline.columns, index = cpiheadline.index)\n",
    "\n",
    "for i in eff_target_diff.columns:\n",
    "    if i == \"Australia\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.025\n",
    "    elif i == \"Canada\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"China\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Germany\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"France\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"UK\":\n",
    "        eff_target_diff.loc[:\"2003-11-28\",i] = cpiheadline.loc[:\"2003-11-28\",i] - 0.025\n",
    "        eff_target_diff.loc[\"2003-12-31\":,i] = cpiheadline.loc[\"2003-12-31\":,i] - 0.02\n",
    "    elif i == \"Italy\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Japan\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.033\n",
    "    elif i == \"Singapore\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"USA\":\n",
    "        eff_target_diff.loc[:\"2011-12-31\",i] = cpiheadline.loc[:\"2011-12-31\",i] - 0.0185\n",
    "        eff_target_diff.loc[\"2012-01-31\":,i] = cpiheadline.loc[\"2012-01-31\":,i] - 0.02\n",
    "    elif i == \"Spain\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.02\n",
    "    elif i == \"Switzerland\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.01\n",
    "    elif i == \"India\":\n",
    "        eff_target_diff.loc[:,i] = cpiheadline.loc[:,i] - 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.012722222222222225"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(eff_target_diff.loc[:\"2002-11-30\", \"Singapore\"])\n",
    "#np.nanmean(eff_target_diff.loc[\"2020-04-30\":, \"Singapore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-718e0d68af44>:15: RuntimeWarning: Mean of empty slice\n",
      "  inflation = np.nanmean(eff_target_diff.iloc[runner-36:runner, j])\n"
     ]
    }
   ],
   "source": [
    "# create the rolling 3-year average of the core inflation\n",
    "\n",
    "# first I have to set up an empty dictionary to store the rolling averages\n",
    "cpiheadline_avg = {}\n",
    "for i in cpiheadline.columns:\n",
    "    cpiheadline_avg[i] = []\n",
    "\n",
    "# next up we iterate over the cpicore data to get the index and safe them in the dictionary\n",
    "runner = len(cpiheadline.index)\n",
    "for i in cpiheadline.index:\n",
    "    if runner == 35:\n",
    "        break\n",
    "    \n",
    "    for j,k in enumerate(cpiheadline.columns):\n",
    "        inflation = np.nanmean(eff_target_diff.iloc[runner-36:runner, j])\n",
    "        cpiheadline_avg[k].insert(0, inflation)\n",
    "    runner -= 1\n",
    "    \n",
    "#cpiheadline_avg\n",
    "cpiheadline_avg_trimmed = pd.DataFrame(cpiheadline_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>India</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Canada</th>\n",
       "      <th>USA</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Australia</th>\n",
       "      <th>China</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>UK</th>\n",
       "      <th>Spain</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Italy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012722</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>-0.040861</td>\n",
       "      <td>0.013686</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.003778</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.040667</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>-0.019139</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>-0.014028</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.003833</td>\n",
       "      <td>0.005778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013278</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>-0.019139</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>-0.040444</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>-0.018917</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>-0.004111</td>\n",
       "      <td>0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>-0.040361</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>-0.018806</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>0.006194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.002639</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.008917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.021597</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>-0.025722</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.012083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.021144</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>-0.024833</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.015167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.020847</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>0.018556</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.017806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.020808</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>-0.023028</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.026306</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.020333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        India  Singapore    Canada       USA     Japan  Australia     China  \\\n",
       "0         NaN  -0.012722  0.004139  0.007306 -0.040861   0.013686 -0.018914   \n",
       "1         NaN  -0.013000  0.004722  0.007167 -0.040667   0.013500 -0.019139   \n",
       "2         NaN  -0.013278  0.005083  0.007083 -0.040500   0.013833 -0.019139   \n",
       "3         NaN  -0.013444  0.005694  0.006917 -0.040444   0.014167 -0.018917   \n",
       "4         NaN  -0.013694  0.006222  0.006694 -0.040361   0.014500 -0.018806   \n",
       "..        ...        ...       ...       ...       ...        ...       ...   \n",
       "240  0.021503   0.004167  0.014000  0.023944 -0.026639   0.002667 -0.000500   \n",
       "241  0.021597   0.005861  0.015278  0.025333 -0.025722   0.004111 -0.001306   \n",
       "242  0.021144   0.007444  0.016417  0.026500 -0.024833   0.005639 -0.002056   \n",
       "243  0.020847   0.009056  0.017389  0.027583 -0.023833   0.007167 -0.002972   \n",
       "244  0.020808   0.010722  0.018222  0.028611 -0.023028   0.008722 -0.004139   \n",
       "\n",
       "     Switzerland        UK     Spain    France   Germany     Italy  \n",
       "0       0.001194 -0.014194  0.014091 -0.003139 -0.003778  0.005556  \n",
       "1       0.000972 -0.014028  0.014500 -0.002778 -0.003833  0.005778  \n",
       "2       0.000750 -0.013889  0.014923 -0.002500 -0.004000  0.006000  \n",
       "3       0.000528 -0.013694  0.015071 -0.002389 -0.004111  0.006139  \n",
       "4       0.000361 -0.013444  0.015267 -0.002056 -0.004167  0.006194  \n",
       "..           ...       ...       ...       ...       ...       ...  \n",
       "240    -0.002639  0.016472  0.014083  0.001833  0.013972  0.008917  \n",
       "241    -0.001778  0.019028  0.015861  0.003278  0.016444  0.012083  \n",
       "242    -0.001056  0.021583  0.017222  0.004528  0.018417  0.015167  \n",
       "243    -0.000194  0.023889  0.018556  0.005778  0.020361  0.017806  \n",
       "244     0.000778  0.026306  0.020028  0.007139  0.022306  0.020333  \n",
       "\n",
       "[245 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpiheadline_avg_trimmed # until here I checked several times whether it is correct and it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-90c02453a451>:21: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  formula_values.iloc[:,j+i*5] = (1/m)*cpiheadline_trimmed[k] +((m-1)/m)*cpiheadline_avg_trimmed[k]\n"
     ]
    }
   ],
   "source": [
    "# now we calculate the value formula:\n",
    "# (1/n)*recent inflation + ((n-1)/n)*effective target inflation for the years: 2, 5, 10, 20, 30\n",
    "\n",
    "# first we need to align the dataframes \n",
    "cpiheadline_trimmed = cpiheadline[35:]\n",
    "cpiheadline_avg_trimmed.set_index(cpiheadline_trimmed.index, inplace = True)\n",
    "\n",
    "# second we create an empty dictionary to fill with the calculations\n",
    "formula_values = {}\n",
    "x = 0\n",
    "for i in cpiheadline_trimmed.columns:\n",
    "    x += 1\n",
    "    for j in [2,5,10,20,30]:\n",
    "        formula_values[f\"{i},{j}\"] = []\n",
    "formula_values = pd.DataFrame(columns = formula_values.keys(), index = cpiheadline_trimmed.index)\n",
    "\n",
    "\n",
    "# now that we have the empty dictionary to fill, we start with caluclating the inflation expectation\n",
    "for i,k in enumerate (cpiheadline_trimmed.columns):\n",
    "    for j,m in enumerate([2,5,10,20,30]):\n",
    "        formula_values.iloc[:,j+i*5] = (1/m)*cpiheadline_trimmed[k] +((m-1)/m)*cpiheadline_avg_trimmed[k]\n",
    "        \n",
    "#formula_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to align the NA's from the ETF with the NA's from the Yields such that we don't get a weight for a date that\n",
    "# we don't have return data for\n",
    "\n",
    "Yield_na = Yield_long.copy()\n",
    "ETF_na = ETF.pct_change().isna()\n",
    "ETF_na\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i,k in enumerate(Yield_na.columns):\n",
    "    if counter == 5:\n",
    "        counter = 0\n",
    "        runner += 1\n",
    "    tmp = ETF_na.iloc[:,runner]\n",
    "    Yield_na.iloc[tmp,i] = np.nan\n",
    "    counter +=1\n",
    "Yield_na\n",
    "\n",
    "\n",
    "# now we have the issue that the Yield_clean data and the Inflation_clean data doesn't have the same sequence of countries\n",
    "# to avoid this we resort the Yield_clean data to fit the Inflation_clean data\n",
    "\n",
    "clean_names = [\"Germany\", \"France\",\"Spain\",\"Italy\",\"United Kingdom\", \"Switzerland\", \"China\", \"Australia\", \"Japan\", \"USA\", \"Canada\", \"Singapore\", \"India\"]\n",
    "\n",
    "# we split the dataframe into the different countries...\n",
    "Germany = Yield_na.iloc[:,:5]\n",
    "France = Yield_na.iloc[:,5:10]\n",
    "Spain = Yield_na.iloc[:,10:15]\n",
    "Italy = Yield_na.iloc[:,15:20]\n",
    "UK = Yield_na.iloc[:,20:25]\n",
    "Switzerland = Yield_na.iloc[:,25:30]\n",
    "China = Yield_na.iloc[:,30:35]\n",
    "Australia = Yield_na.iloc[:,35:40]\n",
    "Japan = Yield_na.iloc[:,40:45]\n",
    "USA = Yield_na.iloc[:,45:50]\n",
    "Canada = Yield_na.iloc[:,50:55]\n",
    "Singapore = Yield_na.iloc[:,55:60]\n",
    "India = Yield_na.iloc[:,60:]\n",
    "\n",
    "# ... and fusion them together to have the same order as the Inflation data (plus dividing by 100 to have same level as Inflation)\n",
    "Yields_aligned = [India, Singapore, Canada, USA, Japan, Australia, China, Switzerland, UK, Spain, France, Germany, Italy]\n",
    "Yields_aligned = pd.concat(Yields_aligned, axis=1)\n",
    "Yields_aligned = Yields_aligned /100\n",
    "#Yields_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a next step we adjust the yield data to have the same lookback as the other data\n",
    "\n",
    "Yield_trimmed = Yields_aligned[35:]\n",
    "\n",
    "Real_yield = pd.DataFrame(0, columns = formula_values.columns, index = formula_values.index)\n",
    "\n",
    "# now we take the difference between yield etf and inflation\n",
    "for i,k in enumerate(formula_values.columns):\n",
    "    for j,l in enumerate(formula_values.index):\n",
    "        Real_yield.iloc[j,i] = Yield_trimmed.iloc[j,i] - formula_values.iloc[j,i]\n",
    "#Real_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-1ebfb3f6f625>:7: RuntimeWarning: Mean of empty slice\n",
      "  temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n",
      "<ipython-input-12-1ebfb3f6f625>:8: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  Real_yield_avg.iloc[:,runner] = temp.values\n",
      "<ipython-input-12-1ebfb3f6f625>:7: RuntimeWarning: Mean of empty slice\n",
      "  temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n"
     ]
    }
   ],
   "source": [
    "# in a final step we will average over the duration of the countries to get one average for each country\n",
    "\n",
    "Real_yield_avg = pd.DataFrame(columns = cpiheadline_avg_trimmed.columns, index = Real_yield.index)\n",
    "\n",
    "runner = 0\n",
    "for i in range(0, len(Yields_aligned.columns)-1, 5):\n",
    "    temp = pd.DataFrame(np.nanmean([Real_yield.iloc[:,i],Real_yield.iloc[:,i+1],Real_yield.iloc[:,i+2],Real_yield.iloc[:,i+3],Real_yield.iloc[:,i+4]], axis = 0))\n",
    "    Real_yield_avg.iloc[:,runner] = temp.values\n",
    "    runner +=1\n",
    "    \n",
    "#Real_yield_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate computeSortWeights into python\n",
    "def compute_sort_weights(sort_variable, n_longs, n_shorts, long_high_values):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        list_of_longs = np.argpartition(-sort_variable, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(sort_variable, n_shorts)[:n_shorts]\n",
    "    else:\n",
    "        list_of_longs = np.argpartition(sort_variable, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(-sort_variable, n_shorts)[:n_shorts]\n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sort_weights_GPT_2(sort_variable, n_longs, n_shorts, long_high_values):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        sort_variable_sorted = -sort_variable  # For long high values, sort descending\n",
    "    else:\n",
    "        sort_variable_sorted = sort_variable   # For long low values, sort ascending\n",
    "    non_nan_assets = ~np.isnan(sort_variable_sorted)\n",
    "    non_nan_count = np.count_nonzero(non_nan_assets)\n",
    "    \n",
    "    # Check if n_shorts is zero\n",
    "    if n_shorts == 0:\n",
    "        if non_nan_count < n_longs:\n",
    "            n_longs = non_nan_count\n",
    "        list_of_longs = np.argpartition(sort_variable_sorted, -n_longs)[-n_longs:]\n",
    "        weights = np.zeros(len(sort_variable))\n",
    "        weights[list_of_longs] = 1 / n_longs\n",
    "        return weights\n",
    "    \n",
    "    # If n_shorts is not zero, handle normally\n",
    "    if non_nan_count < n_longs:\n",
    "        n_longs = non_nan_count\n",
    "        n_shorts = 0\n",
    "    elif n_shorts > 0 and non_nan_count < n_longs + n_shorts:\n",
    "        n_shorts = non_nan_count - n_longs\n",
    "    \n",
    "    if long_high_values:\n",
    "        list_of_longs = np.argpartition(sort_variable_sorted, -n_longs)[-n_longs:]\n",
    "        list_of_shorts = np.argpartition(sort_variable_sorted, n_shorts)[:n_shorts]\n",
    "    else:\n",
    "        list_of_longs = np.argpartition(sort_variable_sorted, n_longs)[:n_longs]\n",
    "        list_of_shorts = np.argpartition(sort_variable_sorted, -n_shorts)[-n_shorts:]\n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sort_weights_GPT(sort_variable, n_longs, n_shorts, long_high_values):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        sort_variable_sorted = -sort_variable  # For long high values, sort descending\n",
    "    else:\n",
    "        sort_variable_sorted = sort_variable   # For long low values, sort ascending\n",
    "    non_nan_assets = ~np.isnan(sort_variable_sorted)\n",
    "    non_nan_count = np.count_nonzero(non_nan_assets)\n",
    "    if non_nan_count < n_longs:\n",
    "        n_longs = non_nan_count\n",
    "        n_shorts = 0\n",
    "    elif n_shorts > 0 and non_nan_count < n_longs + n_shorts:\n",
    "        n_shorts = non_nan_count - n_longs\n",
    "    \n",
    "    if long_high_values:\n",
    "        list_of_longs = np.argpartition(sort_variable_sorted, -n_longs)[-n_longs:]\n",
    "        if n_shorts > 0:\n",
    "            list_of_shorts = np.argpartition(sort_variable_sorted, n_shorts)[:n_shorts]\n",
    "        else:\n",
    "            list_of_shorts = []\n",
    "    else:\n",
    "        list_of_longs = np.argpartition(sort_variable_sorted, n_longs)[:n_longs]\n",
    "        if n_shorts > 0:\n",
    "            list_of_shorts = np.argpartition(sort_variable_sorted, -n_shorts)[-n_shorts:]\n",
    "        else:\n",
    "            list_of_shorts = []\n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    if n_shorts > 0:\n",
    "        weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we take the average of the three Swiss indices\n",
    "\n",
    "\n",
    "\n",
    "# s1 = ETF_price[\"Switzerland 1\"]\n",
    "# s2 = ETF_price[\"Switzerland 2\"]\n",
    "# s3 = ETF_price[\"Switzerland 3\"]\n",
    "\n",
    "#ETF_price.drop([\"Switzerland 2\", \"Switzerland 3\"], axis = 1, inplace = True)\n",
    "#ETF_price.loc[\"2003-11-28\":,\"Switzerland 1\"] = (np.nanmean([s1.loc[\"2003-11-28\":], s2.loc[\"2003-11-28\":], s3.loc[\"2003-11-28\":]], axis = 0))\n",
    "#ETF_price.rename(columns={\"Switzerland 1\": \"Switzerland\"}, inplace = True)\n",
    "#ETF_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>France</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Italy</th>\n",
       "      <th>UK</th>\n",
       "      <th>Swiss comb</th>\n",
       "      <th>China</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>India</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>-0.004171</td>\n",
       "      <td>-0.005380</td>\n",
       "      <td>-0.003788</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>-0.008643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.017969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>-0.005362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>-0.000372</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.021247</td>\n",
       "      <td>0.020407</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.028590</td>\n",
       "      <td>-0.003167</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>-0.007105</td>\n",
       "      <td>0.026820</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.024462</td>\n",
       "      <td>0.035617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.040014</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>-0.039934</td>\n",
       "      <td>-0.045044</td>\n",
       "      <td>-0.040348</td>\n",
       "      <td>-0.026188</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>-0.022093</td>\n",
       "      <td>-0.017501</td>\n",
       "      <td>-0.007295</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>-0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>0.029945</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>0.016199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>-0.026330</td>\n",
       "      <td>-0.025761</td>\n",
       "      <td>-0.023048</td>\n",
       "      <td>-0.015409</td>\n",
       "      <td>-0.033117</td>\n",
       "      <td>-0.008727</td>\n",
       "      <td>-0.023555</td>\n",
       "      <td>-0.015928</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>-0.022819</td>\n",
       "      <td>-0.021471</td>\n",
       "      <td>-0.021232</td>\n",
       "      <td>-0.011076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>0.024957</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>0.029179</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.014041</td>\n",
       "      <td>0.033902</td>\n",
       "      <td>0.024443</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>0.023681</td>\n",
       "      <td>0.033286</td>\n",
       "      <td>0.020357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Germany    France     Spain     Italy        UK  Swiss comb  \\\n",
       "Datum                                                                      \n",
       "2000-01-31 -0.004171 -0.005380 -0.003788 -0.002261 -0.008643         NaN   \n",
       "2000-02-29  0.006663  0.005979  0.005704  0.005947  0.017969         NaN   \n",
       "2000-03-31  0.016454  0.016604  0.016070  0.013889  0.011709         NaN   \n",
       "2000-04-28 -0.000372 -0.000371 -0.000186  0.000278  0.010394         NaN   \n",
       "2000-05-31  0.004095  0.002878  0.002698  0.000185  0.000872         NaN   \n",
       "...              ...       ...       ...       ...       ...         ...   \n",
       "2022-11-30  0.020856  0.021247  0.020407  0.027423  0.028590   -0.003167   \n",
       "2022-12-30 -0.040014 -0.046631 -0.039934 -0.045044 -0.040348   -0.026188   \n",
       "2023-01-31  0.016672  0.022153  0.018742  0.032246  0.026417    0.014935   \n",
       "2023-02-28 -0.026330 -0.025761 -0.023048 -0.015409 -0.033117   -0.008727   \n",
       "2023-03-31  0.026577  0.023355  0.024957  0.022337  0.029179    0.016104   \n",
       "\n",
       "               China  Australia     Japan       USA    Canada  Singapore  \\\n",
       "Datum                                                                      \n",
       "2000-01-31       NaN  -0.002667  0.001062       NaN       NaN        NaN   \n",
       "2000-02-29       NaN   0.021341 -0.005362       NaN       NaN   0.010291   \n",
       "2000-03-31       NaN   0.012913  0.003724       NaN       NaN   0.004587   \n",
       "2000-04-28       NaN   0.003988  0.003371       NaN       NaN   0.005115   \n",
       "2000-05-31       NaN   0.012299  0.006855       NaN       NaN  -0.005588   \n",
       "...              ...        ...       ...       ...       ...        ...   \n",
       "2022-11-30  0.014626   0.014057 -0.007105  0.026820  0.028205   0.024462   \n",
       "2022-12-30  0.030486  -0.022093 -0.017501 -0.007295 -0.016807   0.013594   \n",
       "2023-01-31  0.027221   0.029014 -0.004038  0.026849  0.029945  -0.001737   \n",
       "2023-02-28 -0.023555  -0.015928  0.016255 -0.022819 -0.021471  -0.021232   \n",
       "2023-03-31  0.014041   0.033902  0.024443  0.029306  0.023681   0.033286   \n",
       "\n",
       "               India  \n",
       "Datum                 \n",
       "2000-01-31       NaN  \n",
       "2000-02-29       NaN  \n",
       "2000-03-31       NaN  \n",
       "2000-04-28       NaN  \n",
       "2000-05-31       NaN  \n",
       "...              ...  \n",
       "2022-11-30  0.035617  \n",
       "2022-12-30 -0.014761  \n",
       "2023-01-31  0.016199  \n",
       "2023-02-28 -0.011076  \n",
       "2023-03-31  0.020357  \n",
       "\n",
       "[279 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Monthly Returns out of ETF Prices\n",
    "ETF_price = ETF.copy()\n",
    "ETF_returns = ETF_price.pct_change()\n",
    "ETF_ret = ETF_returns.tail(-1)\n",
    "ETF_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Weights for Momentum\n",
    "\n",
    "# Prep Work\n",
    "nAssets = len(ETF_price.columns) # 13 Countries\n",
    "nMonths = len(ETF_price) # 280 Months of prices (31.12.1999 - 31.03.2023)\n",
    "lookbackStart = 12\n",
    "lookbackEnd = 1\n",
    "firstMonth = lookbackStart + 1 # we can only start computing weights in 13.month bc we have 12 months lookback \n",
    "nLongs = 5\n",
    "nShorts = 5\n",
    "momLongWeights = pd.DataFrame(np.zeros((nMonths, nAssets)))\n",
    "momLSWeights = pd.DataFrame(np.zeros((nMonths, nAssets)))\n",
    "long_weight = np.divide(1,nLongs)\n",
    "short_weight = np.divide(1,nShorts)*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the n columns with maximum value\n",
    "def n_max_row(df, n):\n",
    "    return df.apply(lambda x: x.nlargest(n).index.tolist(), axis=1)\n",
    "\n",
    "def n_min_row(df, n):\n",
    "    return df.apply(lambda x: x.nsmallest(n).index.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Loop to get the Long weights and the Long/Short Weights\n",
    "\n",
    "for month in range(firstMonth, nMonths):\n",
    "     pastReturns = pd.DataFrame(np.divide(ETF_price.iloc[month - lookbackEnd, :], ETF_price.iloc[month - lookbackStart, :]) - 1)\n",
    "     highReturns = pastReturns.nlargest(nLongs,columns=pastReturns.columns)\n",
    "     lowReturns = pastReturns.nsmallest(nShorts,columns=pastReturns.columns)\n",
    "     low_index = lowReturns.index\n",
    "     high_index = highReturns.index\n",
    "     pRet_index = pastReturns.index\n",
    "\n",
    "     high_index_numbers = pRet_index.get_indexer(high_index)\n",
    "     low_index_numbers = pRet_index.get_indexer(low_index)\n",
    "     # Long Weights only\n",
    "     momLongWeights.iloc[month,high_index_numbers] = long_weight\n",
    "     # Long/Short Weights only\n",
    "     momLSWeights.iloc[month,high_index_numbers] = long_weight\n",
    "     momLSWeights.iloc[month,low_index_numbers] = short_weight\n",
    "\n",
    "# Set Index and Column Names again\n",
    "momLongWeights = momLongWeights.set_index(ETF_price.index).copy()\n",
    "momLongWeights.columns = ETF_price.columns\n",
    "\n",
    "momLSWeights = momLSWeights.set_index(ETF_price.index).copy()\n",
    "momLSWeights.columns = ETF_price.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momLSWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momLongWeights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleanup -> Returns in sync with weights!\n",
    "momLongWeights_cut = momLongWeights.iloc[firstMonth:, :] # cut out first 13 months -> first row now is weight calculated at 31.01.2000; keep extra row at end tor Turnover\n",
    "momLSWeights_cut = momLSWeights.iloc[firstMonth:, :] # cut out first 13 months -> first row now is weight calculated at 31.01.2000; keep extra row at end tor Turnover\n",
    "ETF_ret_cut = ETF_ret.iloc[firstMonth :, :] # Not firstMonth+1 bc we dropped one row above in ret calculation -> we need Returns from 28.02.2000\n",
    "dates4Fig = ETF_ret_cut.index\n",
    "nMonths_actual = nMonths - (firstMonth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momLongWeights_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.multiply(ETF_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.multiply(ETF_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate strategy Returns no TC\n",
    "stratReturnsNoTC = pd.DataFrame(np.zeros((nMonths_actual, 2)))\n",
    "# note we only take weights rows until end -1 bc we left one to much in\n",
    "LongStratRet = np.sum(np.multiply(ETF_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1)\n",
    "LSStratRet = np.sum(np.multiply(ETF_ret_cut, momLongWeights_cut.iloc[ : -1, :]), axis=1) # RF monthly must be added!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([LongStratRet,LSStratRet]) #Not done yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-fb6f15460685>:14: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  Carry_3m.iloc[:,i] = Yield_na.iloc[:,i] - Yield_short.iloc[:,runner]\n",
      "<ipython-input-18-fb6f15460685>:18: RuntimeWarning: Mean of empty slice\n",
      "  avg_Carry_3m.iloc[:,i] = np.nanmean([Carry_3m.iloc[:,i*5], Carry_3m.iloc[:,i*5+1], Carry_3m.iloc[:,i*5+2], Carry_3m.iloc[:,i*5+3], Carry_3m.iloc[:,i*5+4]], axis = 0)\n"
     ]
    }
   ],
   "source": [
    "# for carry we will now calculate the differences between the long-term yields (2,5,10,20,30) and short-term yields (1M, 3M)\n",
    "# we will create a dataframe for the 1M and the 3M\n",
    "# I take the Yield_na for the calculation to get the same NA's as the ETF has\n",
    "\n",
    "Carry_3m = pd.DataFrame(columns = Yield_long.columns, index = Yield_long.index)\n",
    "avg_Carry_3m = pd.DataFrame(0, columns = Yield_short.columns, index = Yield_short.index)\n",
    "\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i in range(0,len(Yield_long.columns)):\n",
    "    if counter == 5:\n",
    "        runner += 1\n",
    "        counter = 0\n",
    "    Carry_3m.iloc[:,i] = Yield_na.iloc[:,i] - Yield_short.iloc[:,runner]\n",
    "    counter += 1\n",
    "    \n",
    "for i in range(0,len(Yield_short.columns)):\n",
    "    avg_Carry_3m.iloc[:,i] = np.nanmean([Carry_3m.iloc[:,i*5], Carry_3m.iloc[:,i*5+1], Carry_3m.iloc[:,i*5+2], Carry_3m.iloc[:,i*5+3], Carry_3m.iloc[:,i*5+4]], axis = 0)\n",
    "\n",
    "avg_Carry_3m = avg_Carry_3m / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort function to create the buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmp_Sort(sort_variable, n_longs, n_shorts, long_high_values=True, equal_weights_ls=False):\n",
    "    \"\"\"\n",
    "    Generates portfolio weights based on sort_variable. The function ignores assets for which the sort variable is\n",
    "    missing (NaN). All such assets get a weight of zero in the portfolio. n_longs and n_shorts denote the number of\n",
    "    assets held long and short. When long_high_values is True, assets that have the highest values for sort_variable\n",
    "    are held long and those with the lowest values are held short. Otherwise, the opposite holds.\n",
    "    \"\"\"\n",
    "    # Find the assets with the highest and lowest values of the sort variable\n",
    "    if long_high_values:\n",
    "        sort_variable_sorted = sort_variable  # For long high values, sort descending\n",
    "    else:\n",
    "        sort_variable_sorted = -sort_variable   # For long low values, sort ascending\n",
    "    non_nan_assets = ~np.isnan(sort_variable_sorted)\n",
    "    non_nan_count = np.count_nonzero(non_nan_assets)\n",
    "\n",
    "    \n",
    "    # Check if n_shorts is zero\n",
    "    if n_shorts == 0:\n",
    "        tmp_long = list(sort_variable_sorted)\n",
    "        tmp_long = [-10000000 if pd.isna(x) else x for x in tmp_long]\n",
    "        list_of_longs = np.argsort(tmp_long)[-5:]\n",
    "        \n",
    "        weights = np.zeros(len(sort_variable))\n",
    "        weights[list_of_longs] = 1 / n_longs\n",
    "        return weights\n",
    "\n",
    "    # If n_shorts is not zero, handle normally\n",
    "    if non_nan_count < n_longs:\n",
    "        n_longs = non_nan_count\n",
    "        n_shorts = 0\n",
    "    elif n_shorts > 0 and non_nan_count < n_longs + n_shorts:\n",
    "        n_shorts = non_nan_count - n_longs\n",
    "        \n",
    "    if equal_weights_ls == True:\n",
    "        n_shorts = non_nan_count // 2\n",
    "        n_longs = non_nan_count // 2\n",
    "        \n",
    "    \n",
    "\n",
    "    tmp_long = list(sort_variable_sorted)\n",
    "    tmp_long = [-10000000 if pd.isna(x) else x for x in tmp_long]\n",
    "    list_of_longs = np.argsort(tmp_long)[-n_longs:]\n",
    "        \n",
    "    tmp_short = list(sort_variable_sorted)\n",
    "    tmp_short = [100000000 if pd.isna(x) else x for x in tmp_short]\n",
    "    list_of_shorts = np.argsort(tmp_short)[:n_shorts]\n",
    "    \n",
    "\n",
    "    # Assign the weights to assets in the list of longs and shorts\n",
    "    n_assets = len(sort_variable)\n",
    "    weights = np.zeros(n_assets)\n",
    "    weights[list_of_longs] = 1 / n_longs\n",
    "    weights[list_of_shorts] = -1 / n_shorts\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-6311c5b61576>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ETF_value.rename(columns = {\"Swiss comb\": \"Switzerland\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Value\n",
    "weights = pd.DataFrame(columns = Real_yield_avg.columns, index = Real_yield_avg.index)\n",
    "\n",
    "for i,k in enumerate(Real_yield_avg.index):\n",
    "    temp = pmp_Sort(Real_yield_avg.iloc[i,:], 5,5)\n",
    "    weights.iloc[i,:] = temp\n",
    "    \n",
    "# now we need to align the columns of weights to columns of returns\n",
    "ETF_returns = ETF.pct_change()\n",
    "ETF_value = ETF_returns.iloc[35:,:]\n",
    "ETF_value.rename(columns = {\"Swiss comb\": \"Switzerland\"}, inplace=True)\n",
    "\n",
    "Value_weights = pd.DataFrame(columns = ETF_value.columns, index = ETF_value.index)\n",
    "weights.set_index(ETF_value.index, inplace=True)\n",
    "for i in ETF_value.columns:\n",
    "    Value_weights.loc[:,i] = weights.loc[:,i]\n",
    "    \n",
    "# finally we will insert 0 back until the first values of the other strategies\n",
    "x = Value_weights.copy()\n",
    "Value_weights = pd.DataFrame(0, columns = Carry_weights.columns, index = Carry_weights.index)\n",
    "Value_weights.iloc[35:,:] = x\n",
    "\n",
    "#Value_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry\n",
    "Carry_weights = pd.DataFrame(columns = avg_Carry_3m.columns, index = avg_Carry_3m.index)\n",
    "\n",
    "for i,k in enumerate(avg_Carry_3m.index):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    temp = pmp_Sort(avg_Carry_3m.iloc[i,:], 5, 5)\n",
    "    Carry_weights.iloc[i,:] = temp\n",
    "\n",
    "#Carry_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>France</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Italy</th>\n",
       "      <th>UK</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>China</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Singapore</th>\n",
       "      <th>India</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Germany France Spain Italy        UK Switzerland China Australia  \\\n",
       "Datum                                                                           \n",
       "1999-12-31       NaN    NaN   NaN   NaN       NaN         NaN   NaN       NaN   \n",
       "2000-01-31       0.2    0.2   0.2   0.2      -0.5         0.0   0.0       0.2   \n",
       "2000-02-29       0.2    0.2   0.2   0.2 -0.333333         0.0   0.0 -0.333333   \n",
       "2000-03-31 -0.333333    0.2   0.2   0.2 -0.333333         0.0   0.0 -0.333333   \n",
       "2000-04-28 -0.333333    0.2   0.2   0.2 -0.333333         0.0   0.0 -0.333333   \n",
       "...              ...    ...   ...   ...       ...         ...   ...       ...   \n",
       "2022-11-30      -0.2    0.2   0.2   0.2       0.0        -0.2   0.2       0.2   \n",
       "2022-12-30      -0.2    0.2   0.2   0.2       0.0        -0.2   0.2       0.2   \n",
       "2023-01-31      -0.2    0.2   0.2   0.2       0.0        -0.2   0.2       0.2   \n",
       "2023-02-28      -0.2    0.2   0.2   0.2       0.0        -0.2   0.2       0.2   \n",
       "2023-03-31      -0.2    0.2   0.2   0.2       0.0        -0.2   0.2       0.2   \n",
       "\n",
       "               Japan  USA Canada Singapore India  \n",
       "Datum                                             \n",
       "1999-12-31       NaN  NaN    NaN       NaN   NaN  \n",
       "2000-01-31      -0.5  0.0    0.0       0.0   0.0  \n",
       "2000-02-29 -0.333333  0.0    0.0       0.2   0.0  \n",
       "2000-03-31       0.2  0.0    0.0       0.2   0.0  \n",
       "2000-04-28       0.2  0.0    0.0       0.2   0.0  \n",
       "...              ...  ...    ...       ...   ...  \n",
       "2022-11-30       0.0  0.0   -0.2      -0.2  -0.2  \n",
       "2022-12-30       0.0  0.0   -0.2      -0.2  -0.2  \n",
       "2023-01-31       0.0  0.0   -0.2      -0.2  -0.2  \n",
       "2023-02-28       0.0  0.0   -0.2      -0.2  -0.2  \n",
       "2023-03-31       0.0  0.0   -0.2      -0.2  -0.2  \n",
       "\n",
       "[280 rows x 13 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Carry_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PF weights (not yet working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the following we will combine the weight matrices that we've gathered sofar into two distinct weight matrices for the PF\n",
    "# the PF_weight_score will be a number between -3 and 3 indicating the signals suggesting the country\n",
    "# the PF_weight will just be the sum of the weights\n",
    "\n",
    "Momentum_weights = momLSWeights\n",
    "\n",
    "PF_weights = Value_weights.fillna(0) + Carry_weights.fillna(0) + Momentum_weights.fillna(0)\n",
    "\n",
    "# now we will create the scored weights\n",
    "PF_score = pd.DataFrame(0, columns = Carry_weights.columns, index = Carry_weights.index)\n",
    "PF_weights_score = pd.DataFrame(0, columns = Carry_weights.columns, index = Carry_weights.index)\n",
    "\n",
    "value_pos = Value_weights > 0\n",
    "value_neg = Value_weights < 0\n",
    "carry_pos = Carry_weights > 0\n",
    "carry_neg = Carry_weights < 0\n",
    "mom_pos = Momentum_weights > 0\n",
    "mom_neg = Momentum_weights < 0\n",
    "\n",
    "PF_score[value_pos] = 1\n",
    "PF_score[value_neg] = -1\n",
    "PF_score[carry_pos] += 1\n",
    "PF_score[carry_neg] -= 1\n",
    "PF_score[mom_pos] += 1\n",
    "PF_score[mom_neg] -= 1\n",
    "\n",
    "# print(PF_weights)\n",
    "# print(PF_weights_score)\n",
    "\n",
    "# now we will create the weights for the PF_weights_score\n",
    "x = PF_score > 0\n",
    "y = PF_score < 0\n",
    "PF_pos = PF_score[x]\n",
    "PF_neg = PF_score[y]\n",
    "\n",
    "for i,k in enumerate(PF_pos.index):\n",
    "    pos = sum(PF_pos.iloc[i,:]>0)\n",
    "    if pos == 0:\n",
    "        continue\n",
    "    pos = 1/pos\n",
    "    \n",
    "    neg = sum(PF_score.iloc[i,:]<0)\n",
    "    if neg == 0:\n",
    "        continue\n",
    "    neg = -1/neg\n",
    "    \n",
    "    PF_weights_score.iloc[i,:] = PF_pos.iloc[i,:] * pos\n",
    "    PF_weights_score.iloc[i,:] = PF_neg.iloc[i,:] * neg\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the weights of the different strategies and the returns of the ETF's we can calculate the returns\n",
    "\n",
    "# Value\n",
    "\n",
    "# first we need to align the length of the dataframes and the columns of the two dataframes to match each other\n",
    "Value_returns = Value_weights.mul(ETF_value)\n",
    "#Value_returns\n",
    "\n",
    "# Value_returns_2 = pd.DataFrame(columns = Value_weights.columns, index = ETF_value.index)\n",
    "# for i,k in enumerate(Value_weights.columns):\n",
    "#     Value_returns_2.iloc[:,i] = ETF_value.iloc[:,i] * Value_weights.iloc[:,i]\n",
    "# Value_returns_2.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carry_returns = Carry_weights.mul(ETF_returns)\n",
    "#Carry_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using the ETF_returns, and the respective weights for the calcuclation of the transaction costs\n",
    "# furthermore we need the return of the whole portfolio to calculate the TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TC(asset, PF, weights):\n",
    "    asdfasdf\n",
    "    return ret\n",
    "\n",
    "TC(Momentum, Momentum, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting returns to Euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = df[[\"MSCI_EU\"]]\n",
    "benchmark = benchmark.loc[\"1999-12-31 00:00:00\":\"2022-09-30 00:00:00\"]\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_mtl_ret = mtl_ret = benchmark.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "bm_mtl_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare momentum result vs benchmark\n",
    "comparison = pd.DataFrame(bm_mtl_ret)\n",
    "comparison[\"mom_ret\"] = profits\n",
    "comparison.rename(columns={ comparison.columns[0]: \"bench_ret\" }, inplace = True)\n",
    "comparison[\"bench_indexed\"] = comparison[\"bench_ret\"].add(1).cumprod()\n",
    "comparison[\"mom_indexed\"] = comparison[\"mom_ret\"].add(1).cumprod()\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(comparison.index,comparison.mom_indexed, label=\"Momentum\", color=\"red\")\n",
    "ax.plot(comparison.index,comparison.bench_indexed, label=\"MSCI EU\", color=\"blue\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_ylabel('Monthly Returns')\n",
    "ax.set_title(\"Momentum long/short 5 sectors monthly rebalancing vs MSCI EU, indexed 31.12.1999\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa336b74a8cbeead930f17f553be49714fc6c4491fbee50d1179d377ec590ae0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
