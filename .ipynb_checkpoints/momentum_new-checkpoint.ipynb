{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can recall from critisicm regarding this presentation:\n",
    "\n",
    "- did not take the equal weighted as benchmark\n",
    "- use total return indices (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import required Packages ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "sb.set_style(\"ticks\")\n",
    "sb.mpl.rc(\"figure\", figsize=(16,8))\n",
    "sb.mpl.rc(\"font\", size=14)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "# little function for later\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawdata is direct import from excel\n",
    "\n",
    "# Import of excel data, sheet by sheet\n",
    "xls_ETF = pd.ExcelFile(\"1_Data/Data_ETF_YIELDS_1.0.xlsx\")\n",
    "xls_inflation = pd.ExcelFile(\"1_Data/Data_INFLATION_1.0.xlsm\")\n",
    "\n",
    "ETF_raw = pd.DataFrame(pd.read_excel(xls_ETF, 1))\n",
    "Yield_raw = pd.DataFrame(pd.read_excel(xls_ETF, 2))\n",
    "\n",
    "Yield_short_raw = pd.DataFrame(pd.read_excel(xls_ETF, 3))\n",
    "\n",
    "cpicore_raw = pd.DataFrame(pd.read_excel(xls_inflation, 0))\n",
    "targetrates_raw = pd.DataFrame(pd.read_excel(xls_inflation, 1))\n",
    "#rawdata.columns = [\"Trading_day\", \"Date\", \"MSCI_EU\", \"Healthcare\", \"Finacials\", \"Consumer_staples\",\"Industrials\",\"Consumer_discretionary\",\"Materials\", \"Information_technology\", \"Energy\", \"Utilities\", \"Communication_services\",\"Real_estate\"]\n",
    "\n",
    "\n",
    "# keep a safe copy of the rawdata to compare the changes\n",
    "ETF = ETF_raw.copy()\n",
    "Yield = Yield_raw.copy()\n",
    "Yield_short = Yield_short_raw.copy()\n",
    "cpicore = cpicore_raw.copy()\n",
    "targetrates = targetrates_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns in which only text is and safe them separately --> ONLY RUN ONCE\n",
    "ETF_text = ETF.iloc[0,:]\n",
    "Yield_text = Yield.iloc[0,:]\n",
    "Yield_short_text = Yield_short.iloc[0,:]\n",
    "cpicore_text = cpicore.iloc[0:1,:]\n",
    "\n",
    "\n",
    "ETF.drop([0], inplace = True)\n",
    "Yield.drop([0], inplace = True)\n",
    "Yield_short.drop([0], inplace = True)\n",
    "cpicore.drop([0,1], inplace = True)\n",
    "\n",
    "# Set date as index\n",
    "ETF.set_index(\"Dates\", inplace=True)\n",
    "Yield.set_index(\"Dates\", inplace=True)\n",
    "Yield_short.set_index(\"Dates\", inplace=True)\n",
    "cpicore.set_index(\"Dates\", inplace=True)\n",
    "targetrates.set_index(\"Dates\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent infl – the average of the headline and core annual CPI inflation rate\n",
    "--> we don't have headline inflation\n",
    "\n",
    "\n",
    "Effective target infl - The effective inflation target is the mean of the target range announced or implied by the authorities plus an adjusted for past “target misses”, which is the last 3 years’ average gap between actual inflation and the target means\n",
    "--> we don't have target rates for all countries --> use 2.5 as target rate\n",
    "\n",
    "Formula: (1/n)*recent infl + ((n-1)/n)*effective target infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-526646c4995a>:16: RuntimeWarning: Mean of empty slice\n",
      "  inflation = np.nanmean(cpicore.iloc[runner-36:runner, j])\n"
     ]
    }
   ],
   "source": [
    "# create the rolling 3-year average of the core inflation\n",
    "\n",
    "# first I have to set up an empty dictionary to store the rolling averages\n",
    "cpicore_avg = {}\n",
    "for i in cpicore.columns:\n",
    "    cpicore_avg[i] = []\n",
    "\n",
    "# next up we iterate over the cpicore data to get the index and safe them in the dictionary\n",
    "indices_reverse = cpicore.index[::-1]\n",
    "runner = len(indices_reverse)\n",
    "for i in indices_reverse:\n",
    "    if runner == 35:\n",
    "        break\n",
    "    \n",
    "    for j,k in enumerate(cpicore.columns):\n",
    "        inflation = np.nanmean(cpicore.iloc[runner-36:runner, j])\n",
    "        cpicore_avg[k].append(inflation)\n",
    "    runner -= 1\n",
    "    \n",
    "#cpicore_avg\n",
    "cpicore_avg_trimmed = pd.DataFrame(cpicore_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate the difference between 3-year average and target inflation\n",
    "\n",
    "eff_target_inf = dict(cpicore_avg)\n",
    "\n",
    "# special cases (Australia, Canada, UK, Japan, US, Switzerland) for which we have an actual target\n",
    "for key in cpicore_avg.keys():\n",
    "    if key == \"Australia\":\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k >= 2.0 and k <= 3.0:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            elif k < 2.0:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 2\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 3\n",
    "                \n",
    "    elif key == \"Canada\":\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k >= 1.0 and k <= 3.0:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            elif k < 2.0:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 1\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 3\n",
    "                \n",
    "    elif key == \"United Kingdom\":\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k == 2.0:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 2\n",
    "                \n",
    "    elif key == \"Japan\":\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k == 3.3:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 3.3\n",
    "                \n",
    "    elif key == \"United States\":\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k == 2.0:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 2\n",
    "                \n",
    "    elif key == \"Switzerland\":\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k >= 0.0 and k <= 2.0:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            elif k < 0.0:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 0\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 2\n",
    "                \n",
    "    else:\n",
    "        for i,k in enumerate(cpicore_avg[key]):\n",
    "            if k == 2.5:\n",
    "                eff_target_inf[key][i] = 0\n",
    "            else:\n",
    "                eff_target_inf[key][i] = eff_target_inf[key][i] - 2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we calculate the value formula:\n",
    "# (1/n)*recent inflation + ((n-1)/n)*effective target inflation for the years: 2, 5, 10, 20, 30\n",
    "\n",
    "# first we need to align the dataframes \n",
    "cpicore_trimmed = cpicore[35:]\n",
    "#cpicore_avg_trimmed = pd.DataFrame(cpicore_avg)\n",
    "cpicore_avg_trimmed.set_index(cpicore_trimmed.index, inplace = True)\n",
    "\n",
    "# second we create an empty dictionary to fill with the calculations\n",
    "formula_values = {}\n",
    "x = 0\n",
    "for i in cpicore_trimmed.columns:\n",
    "    x += 1\n",
    "    for j in [2,5,10,20,30]:\n",
    "        formula_values[f\"{x},{j}\"] = []\n",
    "#formula_values\n",
    "\n",
    "# now that we have the empty dictionary to fill, we start with caluclating the inflation expectation\n",
    "keys = list(formula_values.keys())\n",
    "\n",
    "runner = 0\n",
    "for i,k in enumerate (cpicore_trimmed.columns):\n",
    "    for j in [2,5,10,20,30]:\n",
    "        formula_values[keys[runner]].append((1/j)*cpicore_trimmed[k] +((j-1)/j)*cpicore_avg_trimmed[k])\n",
    "        runner += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a next step we adjust the yield data to have the same lookback as the other data\n",
    "\n",
    "Yield_trimmed = Yield[35:]\n",
    "\n",
    "Real_yield = pd.DataFrame(columns = Yield_trimmed.columns, index = Yield_trimmed.index)\n",
    "\n",
    "# here we calculate the difference between the yield etf and the inflation\n",
    "for i,k in enumerate(Real_yield.columns):\n",
    "    key = keys[i]\n",
    "    for j,l in enumerate(Real_yield.index):\n",
    "        Real_yield.iloc[j,i] = Yield_trimmed.iloc[j,i] - formula_values[key][0][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a final step we will now take the average of the countries different maturities yields\n",
    "\n",
    "countries = Real_yield.columns\n",
    "avg_yield_countries = {}\n",
    "for i in range(0,len(countries),5):\n",
    "    avg_yield_countries[countries[i]] = []\n",
    "    \n",
    "countries = list(avg_yield_countries.keys())\n",
    "\n",
    "\n",
    "for i,k in enumerate(avg_yield_countries.keys()):\n",
    "    for j,l in enumerate(Real_yield.index):\n",
    "        m = 0\n",
    "        for f in range(0,5):\n",
    "            m = m + 1/5 * Real_yield.iloc[j,f+5*i]\n",
    "        avg_yield_countries[countries[i]].append(m)\n",
    "\n",
    "avg_yield_countries = pd.DataFrame(avg_yield_countries)\n",
    "#avg_yield_countries\n",
    "\n",
    "# finally we have to search for the maximum in each row\n",
    "\n",
    "maximum_value = avg_yield_countries.idxmax(axis=1)\n",
    "#maximum_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             UK\n",
       "1             UK\n",
       "2             UK\n",
       "3             UK\n",
       "4             UK\n",
       "         ...    \n",
       "240    Australia\n",
       "241    Australia\n",
       "242    Australia\n",
       "243    Australia\n",
       "244    Australia\n",
       "Length: 245, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start off by copying the dataframe and initiating a new empty dataframe to store the return\n",
    "\n",
    "ETF_tr = ETF.copy()\n",
    "ETF_returns = pd.DataFrame(columns = ETF_tr.columns, index = ETF_tr.index)\n",
    "\n",
    "for i,k in enumerate(ETF_tr.index):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    for j,m in enumerate(ETF_tr.columns):\n",
    "        ETF_returns.iloc[i,j] = (ETF_tr.iloc[i,j]/ETF_tr.iloc[i-1,j])-1\n",
    "\n",
    "\n",
    "# here we convert the values to numeric in order to take the maximum afterwards\n",
    "ETF_returns = ETF_returns.apply(pd.to_numeric)\n",
    "\n",
    "# finally we search for the country with the highest momentum and store the values\n",
    "maximum_mom = ETF_returns.idxmax(axis = 1, skipna = True)\n",
    "#maximum_mom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for carry we will now calculate the differences between the long-term yields (2,5,10,20,30) and short-term yields (1M, 3M)\n",
    "# we will create a dataframe for the 1M and the 3M\n",
    "\n",
    "Carry_1m = pd.DataFrame(columns = Yield.columns, index = Yield.index)\n",
    "Carry_3m = pd.DataFrame(columns = Yield.columns, index = Yield.index)\n",
    "avg_Carry_1m = pd.DataFrame(0, columns = countries, index = Yield.index)\n",
    "avg_Carry_3m = pd.DataFrame(0, columns = countries, index = Yield.index)\n",
    "\n",
    "# next we will iterate through all the columns of the yields and substract the short-term rate\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i,k in enumerate(Yield.columns):\n",
    "    if counter == 5:\n",
    "        counter = 0\n",
    "        runner += 2\n",
    "    counter += 1\n",
    "    Carry_1m.iloc[:,i] = Yield.iloc[:,i] - Yield_short.iloc[:,runner]\n",
    "    Carry_3m.iloc[:,i] = Yield.iloc[:,i] - Yield_short.iloc[:,runner+1]\n",
    "    \n",
    "# next we will equal weight the carry signal among the countries\n",
    "for i in range(len(countries)):\n",
    "    j = 0\n",
    "    while j != 5:\n",
    "        avg_Carry_1m.iloc[:,i] += 1/5 * Carry_1m.iloc[:,i+j]\n",
    "        avg_Carry_3m.iloc[:,i] += 1/5 * Carry_3m.iloc[:,i+j]\n",
    "        j += 1\n",
    "        \n",
    "# change data values from object to float\n",
    "avg_Carry_1m = avg_Carry_1m.apply(pd.to_numeric)\n",
    "avg_Carry_3m = avg_Carry_3m.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-4d5b512b5aba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mrunner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCarry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mavg_Carry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrunner\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCarry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mavg_Carry_3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrunner\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCarry_3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCarry_3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mrunner\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n\u001b[0;32m   1047\u001b[0m                  where=where)\n\u001b[1;32m-> 1048\u001b[1;33m     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_divide_by_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[0misbad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36m_divide_by_count\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# for carry we will now calculate the differences between the long-term yields (2,5,10,20,30) and short-term yields (1M, 3M)\n",
    "# we will create a dataframe for the 1M and the 3M\n",
    "\n",
    "Carry_1m = pd.DataFrame(columns = Yield.columns, index = Yield.index)\n",
    "Carry_3m = pd.DataFrame(columns = Yield.columns, index = Yield.index)\n",
    "avg_Carry_1m = pd.DataFrame(0, columns = countries, index = Yield.index)\n",
    "avg_Carry_3m = pd.DataFrame(0, columns = countries, index = Yield.index)\n",
    "\n",
    "# next we will iterate through all the columns of the yields and substract the short-term rate\n",
    "runner = 0\n",
    "counter = 0\n",
    "for i,k in enumerate(Yield.columns):\n",
    "    if counter == 5:\n",
    "        counter = 0\n",
    "        runner += 2\n",
    "    counter += 1\n",
    "    Carry_1m.iloc[:,i] = Yield.iloc[:,i] - Yield_short.iloc[:,runner]\n",
    "    Carry_3m.iloc[:,i] = Yield.iloc[:,i] - Yield_short.iloc[:,runner+1]\n",
    "    \n",
    "# next we will equal weight the carry signal among the countries\n",
    "Carry_1m.iloc[2:66,30:35] = 0\n",
    "\n",
    "runner = 0\n",
    "for i in range(0,len(Carry_1m.columns)-1, 5):\n",
    "    avg_Carry_1m.iloc[:,runner] = np.nanmean([Carry_1m.iloc[:,i], Carry_1m.iloc[:,i+1], Carry_1m.iloc[:,i+2], Carry_1m.iloc[:,i+3], Carry_1m.iloc[:,i+4]], axis = 0)\n",
    "    avg_Carry_3m.iloc[:,runner] = np.nanmean([Carry_3m.iloc[:,i], Carry_3m.iloc[:,i+1], Carry_3m.iloc[:,i+2], Carry_3m.iloc[:,i+3], Carry_3m.iloc[:,i+4]], axis = 0)\n",
    "    runner += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "# change data values from object to float\n",
    "avg_Carry_1m = avg_Carry_1m.apply(pd.to_numeric)\n",
    "avg_Carry_3m = avg_Carry_3m.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>China</th>\n",
       "      <th>China.1</th>\n",
       "      <th>China.2</th>\n",
       "      <th>China.3</th>\n",
       "      <th>China.4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-31</th>\n",
       "      <td>2.048</td>\n",
       "      <td>2.458</td>\n",
       "      <td>3.308</td>\n",
       "      <td>4.113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-28</th>\n",
       "      <td>2.04</td>\n",
       "      <td>2.552</td>\n",
       "      <td>2.971</td>\n",
       "      <td>4.113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-31</th>\n",
       "      <td>1.954</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.982</td>\n",
       "      <td>4.113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-06-30</th>\n",
       "      <td>2.233</td>\n",
       "      <td>2.703</td>\n",
       "      <td>3.14</td>\n",
       "      <td>4.113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-31</th>\n",
       "      <td>2.362</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.288</td>\n",
       "      <td>4.113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            China China.1 China.2 China.3 China.4\n",
       "Dates                                            \n",
       "2000-02-29    NaN     NaN     NaN     NaN     NaN\n",
       "2000-03-31    NaN     NaN     NaN     NaN     NaN\n",
       "2000-04-28    NaN     NaN     NaN     NaN     NaN\n",
       "2000-05-31    NaN     NaN     NaN     NaN     NaN\n",
       "2000-06-30    NaN     NaN     NaN     NaN     NaN\n",
       "...           ...     ...     ...     ...     ...\n",
       "2006-03-31  2.048   2.458   3.308   4.113     NaN\n",
       "2006-04-28   2.04   2.552   2.971   4.113     NaN\n",
       "2006-05-31  1.954     2.5   2.982   4.113     NaN\n",
       "2006-06-30  2.233   2.703    3.14   4.113     NaN\n",
       "2006-07-31  2.362    2.77   3.288   4.113     NaN\n",
       "\n",
       "[78 rows x 5 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Carry_1m.iloc[2:66,30:35] = 1\n",
    "Yield.iloc[2:80,30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3345000000000002, 1.4124999999999996], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.nanmean([Carry_1m.iloc[0:2,0], Carry_1m.iloc[0:2,1]], axis = 0)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dates\n",
       "1999-12-31   NaN\n",
       "2000-01-31   NaN\n",
       "Name: Germany, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Carry_1m.iloc[0:2,0].sub(np.nan, fill_value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort function to create the buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmp_sort(pandas_DataFrame, nMax):\n",
    "    top_bucket = {}\n",
    "    bottom_bucket = {}\n",
    "    for i,k in enumerate(pandas_DataFrame.index):\n",
    "        top_bucket[k] = []\n",
    "        bottom_bucket[k] = []\n",
    "        a = pandas_DataFrame.iloc[i]\n",
    "        for j in range(5):\n",
    "            x = a.idxmax()\n",
    "            y = a.idxmin()\n",
    "            if isNaN(x) and isNaN(y):\n",
    "                break\n",
    "            top_bucket[k].append(x)\n",
    "            bottom_bucket[k].append(y)\n",
    "            a = a.drop([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bucket = {}\n",
    "bottom_bucket = {}\n",
    "for i,k in enumerate(avg_yield_countries.index):\n",
    "    top_bucket[k] = []\n",
    "    bottom_bucket[k] = []\n",
    "    a = avg_yield_countries.iloc[i]\n",
    "    for i in range(3):\n",
    "        x = a.idxmax()\n",
    "        y = a.idxmin()\n",
    "        if isNaN(x):\n",
    "            continue\n",
    "        else:\n",
    "            top_bucket[k].append(x)\n",
    "            a = a.drop(x)\n",
    "        if isNaN(y):\n",
    "            continue\n",
    "        else:\n",
    "            bottom_bucket[k].append(y)\n",
    "            a = a.drop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['UK', 'Germany', 'Canada'], 1: ['UK', 'Germany', 'Canada'], 2: ['UK', 'Canada', 'Germany'], 3: ['UK', 'Canada', 'Italy'], 4: ['UK', 'Canada', 'Italy'], 5: ['UK', 'Canada', 'Italy'], 6: ['UK', 'Italy', 'Canada'], 7: ['UK', 'Italy', 'Canada'], 8: ['UK', 'Italy', 'Canada'], 9: ['UK', 'Canada', 'Italy'], 10: ['UK', 'Canada', 'Italy'], 11: ['UK', 'Canada', 'Italy'], 12: ['UK', 'Canada', 'Italy'], 13: ['UK', 'Canada', 'Italy'], 14: ['UK', 'Canada', 'Italy'], 15: ['UK', 'Canada', 'Italy'], 16: ['UK', 'Canada', 'Italy'], 17: ['UK', 'Canada', 'Italy'], 18: ['UK', 'Canada', 'Italy'], 19: ['UK', 'Canada', 'Italy'], 20: ['UK', 'Canada', 'Italy'], 21: ['UK', 'Canada', 'Italy'], 22: ['UK', 'Canada', 'Italy'], 23: ['UK', 'Canada', 'Italy'], 24: ['UK', 'Canada', 'Italy'], 25: ['UK', 'Canada', 'Italy'], 26: ['UK', 'Canada', 'Italy'], 27: ['UK', 'Canada', 'Italy'], 28: ['UK', 'Canada', 'Italy'], 29: ['UK', 'Canada', 'Italy'], 30: ['UK', 'Canada', 'Italy'], 31: ['UK', 'Canada', 'Italy'], 32: ['UK', 'Canada', 'Italy'], 33: ['UK', 'Canada', 'Italy'], 34: ['UK', 'Canada', 'Italy'], 35: ['UK', 'Canada', 'Italy'], 36: ['UK', 'Canada', 'Italy'], 37: ['UK', 'Canada', 'Italy'], 38: ['UK', 'Canada', 'Italy'], 39: ['UK', 'Canada', 'Italy'], 40: ['UK', 'Italy', 'Canada'], 41: ['UK', 'Canada', 'Italy'], 42: ['UK', 'Italy', 'Canada'], 43: ['UK', 'Italy', 'Canada'], 44: ['UK', 'Italy', 'Canada'], 45: ['UK', 'Italy', 'Canada'], 46: ['UK', 'Italy', 'Canada'], 47: ['UK', 'Italy', 'Canada'], 48: ['UK', 'Italy', 'Canada'], 49: ['UK', 'Italy', 'Canada'], 50: ['UK', 'Italy', 'Canada'], 51: ['UK', 'Italy', 'Canada'], 52: ['UK', 'Italy', 'Canada'], 53: ['UK', 'Italy', 'Canada'], 54: ['UK', 'Italy', 'Canada'], 55: ['UK', 'Italy', 'Canada'], 56: ['UK', 'Canada', 'Italy'], 57: ['UK', 'Canada', 'Italy'], 58: ['UK', 'Italy', 'Canada'], 59: ['UK', 'Italy', 'Canada'], 60: ['UK', 'Italy', 'Canada'], 61: ['UK', 'Italy', 'Canada'], 62: ['UK', 'Italy', 'Canada'], 63: ['UK', 'Italy', 'France'], 64: ['UK', 'Italy', 'France'], 65: ['UK', 'Italy', 'France'], 66: ['UK', 'Italy', 'France'], 67: ['UK', 'Italy', 'France'], 68: ['UK', 'Italy', 'France'], 69: ['Italy', 'UK', 'France'], 70: ['Italy', 'UK', 'Canada'], 71: ['Italy', 'UK', 'Canada'], 72: ['Italy', 'UK', 'Canada'], 73: ['Italy', 'UK', 'Canada'], 74: ['Italy', 'UK', 'Canada'], 75: ['Italy', 'UK', 'Canada'], 76: ['Italy', 'Canada', 'UK'], 77: ['Italy', 'Canada', 'UK'], 78: ['Canada', 'Italy', 'UK'], 79: ['Canada', 'Italy', 'UK'], 80: ['Canada', 'UK', 'Italy'], 81: ['Canada', 'Italy', 'UK'], 82: ['Canada', 'Italy', 'UK'], 83: ['Canada', 'Italy', 'UK'], 84: ['Canada', 'Italy', 'UK'], 85: ['Canada', 'UK', 'Italy'], 86: ['Italy', 'UK', 'Canada'], 87: ['UK', 'Canada', 'Italy'], 88: ['Canada', 'UK', 'Italy'], 89: ['Canada', 'UK', 'Italy'], 90: ['Italy', 'Canada', 'UK'], 91: ['Italy', 'UK', 'Canada'], 92: ['Italy', 'UK', 'Canada'], 93: ['Italy', 'UK', 'Canada'], 94: ['Italy', 'UK', 'Canada'], 95: ['Italy', 'UK', 'Canada'], 96: ['Italy', 'UK', 'Canada'], 97: ['Italy', 'UK', 'Canada'], 98: ['Italy', 'UK', 'France'], 99: ['Italy', 'UK', 'France'], 100: ['Italy', 'UK', 'France'], 101: ['Italy', 'UK', 'France'], 102: ['Italy', 'UK', 'France'], 103: ['Italy', 'UK', 'France'], 104: ['Italy', 'France', 'UK'], 105: ['Italy', 'UK', 'France'], 106: ['Italy', 'UK', 'France'], 107: ['Italy', 'France', 'UK'], 108: ['Italy', 'France', 'UK'], 109: ['Italy', 'France', 'UK'], 110: ['Italy', 'France', 'UK'], 111: ['Italy', 'France', 'UK'], 112: ['Italy', 'Singapore', 'France'], 113: ['Italy', 'Singapore', 'France'], 114: ['Italy', 'Singapore', 'France'], 115: ['Italy', 'Singapore', 'France'], 116: ['Italy', 'Singapore', 'France'], 117: ['Italy', 'Singapore', 'France'], 118: ['Italy', 'Singapore', 'France'], 119: ['Italy', 'Singapore', 'France'], 120: ['Italy', 'Singapore', 'France'], 121: ['Italy', 'Singapore', 'UK'], 122: ['Italy', 'Singapore', 'UK'], 123: ['Italy', 'Singapore', 'UK'], 124: ['Italy', 'Singapore', 'UK'], 125: ['Italy', 'Singapore', 'UK'], 126: ['Italy', 'Singapore', 'UK'], 127: ['Italy', 'Singapore', 'UK'], 128: ['Italy', 'Singapore', 'UK'], 129: ['Italy', 'Singapore', 'UK'], 130: ['Italy', 'Singapore', 'UK'], 131: ['Italy', 'Singapore', 'UK'], 132: ['Italy', 'Singapore', 'UK'], 133: ['Italy', 'Singapore', 'UK'], 134: ['India', 'Singapore', 'Italy'], 135: ['Singapore', 'Italy', 'UK'], 136: ['Singapore', 'Italy', 'UK'], 137: ['Singapore', 'Italy', 'UK'], 138: ['Singapore', 'Italy', 'UK'], 139: ['Singapore', 'Italy', 'UK'], 140: ['Singapore', 'UK', 'Italy'], 141: ['Singapore', 'Italy', 'UK'], 142: ['Singapore', 'UK', 'Italy'], 143: ['Singapore', 'Italy', 'UK'], 144: ['Singapore', 'Italy', 'UK'], 145: ['Singapore', 'Italy', 'UK'], 146: ['Singapore', 'Italy', 'UK'], 147: ['Singapore', 'UK', 'Italy'], 148: ['Singapore', 'UK', 'Italy'], 149: ['Singapore', 'UK', 'Italy'], 150: ['Singapore', 'UK', 'Italy'], 151: ['Singapore', 'Italy', 'UK'], 152: ['Singapore', 'UK', 'Italy'], 153: ['Singapore', 'UK', 'Italy'], 154: ['Singapore', 'UK', 'Italy'], 155: ['Singapore', 'UK', 'Canada'], 156: ['Singapore', 'UK', 'Italy'], 157: ['Singapore', 'UK', 'Italy'], 158: ['Singapore', 'UK', 'Italy'], 159: ['Singapore', 'UK', 'Italy'], 160: ['Singapore', 'UK', 'Italy'], 161: ['Singapore', 'UK', 'Italy'], 162: ['Singapore', 'UK', 'Italy'], 163: ['Singapore', 'UK', 'Italy'], 164: ['Singapore', 'Italy', 'UK'], 165: ['China', 'Singapore', 'Italy'], 166: ['China', 'Singapore', 'Italy'], 167: ['China', 'Singapore', 'Italy'], 168: ['Australia', 'Singapore', 'China'], 169: ['Australia', 'Singapore', 'China'], 170: ['Australia', 'China', 'Singapore'], 171: ['Australia', 'China', 'Singapore'], 172: ['Australia', 'China', 'Singapore'], 173: ['Australia', 'China', 'Singapore'], 174: ['Australia', 'China', 'Singapore'], 175: ['Australia', 'China', 'Singapore'], 176: ['Australia', 'China', 'Singapore'], 177: ['Australia', 'China', 'Singapore'], 178: ['Australia', 'China', 'Singapore'], 179: ['Australia', 'China', 'Singapore'], 180: ['Australia', 'China', 'Singapore'], 181: ['Australia', 'China', 'Singapore'], 182: ['Australia', 'China', 'Singapore'], 183: ['Australia', 'China', 'Singapore'], 184: ['Australia', 'China', 'Singapore'], 185: ['Australia', 'China', 'Singapore'], 186: ['Australia', 'China', 'Singapore'], 187: ['Australia', 'China', 'Singapore'], 188: ['Australia', 'China', 'Singapore'], 189: ['Australia', 'China', 'Singapore'], 190: ['Australia', 'China', 'Singapore'], 191: ['Australia', 'China', 'Singapore'], 192: ['Australia', 'China', 'Singapore'], 193: ['Australia', 'China', 'Singapore'], 194: ['Australia', 'China', 'Singapore'], 195: ['Australia', 'China', 'Singapore'], 196: ['Australia', 'China', 'Singapore'], 197: ['Australia', 'China', 'Singapore'], 198: ['China', 'Australia', 'Singapore'], 199: ['China', 'Australia', 'Singapore'], 200: ['China', 'Australia', 'Singapore'], 201: ['China', 'Australia', 'Singapore'], 202: ['China', 'Australia', 'Singapore'], 203: ['China', 'Australia', 'Singapore'], 204: ['China', 'Australia', 'Singapore'], 205: ['China', 'Australia', 'Singapore'], 206: ['China', 'Australia', 'Singapore'], 207: ['China', 'Australia', 'Singapore'], 208: ['China', 'Australia', 'Singapore'], 209: ['Australia', 'China', 'Italy'], 210: ['Australia', 'China', 'Singapore'], 211: ['China', 'Australia', 'Singapore'], 212: ['China', 'Australia', 'Singapore'], 213: ['China', 'Australia', 'Singapore'], 214: ['China', 'Australia', 'Singapore'], 215: ['China', 'Australia', 'Singapore'], 216: ['China', 'Australia', 'Singapore'], 217: ['Australia', 'China', 'Singapore'], 218: ['Australia', 'China', 'Singapore'], 219: ['Australia', 'China', 'Singapore'], 220: ['Australia', 'China', 'Singapore'], 221: ['Australia', 'China', 'Singapore'], 222: ['Australia', 'China', 'Singapore'], 223: ['Australia', 'China', 'Singapore'], 224: ['Australia', 'China', 'Singapore'], 225: ['Australia', 'China', 'Singapore'], 226: ['Australia', 'Singapore', 'China'], 227: ['Australia', 'Singapore', 'China'], 228: ['Australia', 'Singapore', 'China'], 229: ['Australia', 'Singapore', 'China'], 230: ['Australia', 'Singapore', 'China'], 231: ['Australia', 'Singapore', 'China'], 232: ['Australia', 'Singapore', 'China'], 233: ['Australia', 'Singapore', 'Italy'], 234: ['Australia', 'Singapore', 'Italy'], 235: ['Australia', 'Singapore', 'Italy'], 236: ['Australia', 'Singapore', 'Italy'], 237: ['Australia', 'Singapore', 'Italy'], 238: ['Australia', 'Singapore', 'UK'], 239: ['Australia', 'Singapore', 'Italy'], 240: ['Australia', 'Singapore', 'UK'], 241: ['Australia', 'Italy', 'Singapore'], 242: ['Australia', 'Singapore', 'Italy'], 243: ['Australia', 'Singapore', 'Italy'], 244: ['Australia', 'Singapore', 'Italy']}\n",
      "{0: ['Switzerland', 'Japan', 'France'], 1: ['Switzerland', 'Japan', 'France'], 2: ['Japan', 'Switzerland', 'France'], 3: ['Switzerland', 'Japan', 'France'], 4: ['Japan', 'Switzerland', 'France'], 5: ['Japan', 'Switzerland', 'France'], 6: ['Japan', 'Switzerland', 'France'], 7: ['Japan', 'Switzerland', 'France'], 8: ['Japan', 'Switzerland', 'France'], 9: ['Japan', 'Switzerland', 'France'], 10: ['Japan', 'Switzerland', 'France'], 11: ['Japan', 'Switzerland', 'France'], 12: ['Japan', 'Switzerland', 'France'], 13: ['Japan', 'Switzerland', 'France'], 14: ['Japan', 'Switzerland', 'France'], 15: ['Japan', 'Switzerland', 'Germany'], 16: ['Japan', 'Switzerland', 'France'], 17: ['Japan', 'Switzerland', 'France'], 18: ['Japan', 'Switzerland', 'France'], 19: ['Japan', 'Switzerland', 'France'], 20: ['Japan', 'Switzerland', 'France'], 21: ['Japan', 'Switzerland', 'France'], 22: ['Japan', 'Switzerland', 'France'], 23: ['Japan', 'Switzerland', 'France'], 24: ['Switzerland', 'Japan', 'France'], 25: ['Switzerland', 'Japan', 'France'], 26: ['Switzerland', 'Japan', 'France'], 27: ['Switzerland', 'Japan', 'Germany'], 28: ['Switzerland', 'Japan', 'France'], 29: ['Switzerland', 'Japan', 'France'], 30: ['Switzerland', 'Japan', 'Germany'], 31: ['Switzerland', 'Japan', 'Germany'], 32: ['Switzerland', 'Japan', 'Germany'], 33: ['Switzerland', 'Japan', 'France'], 34: ['Switzerland', 'Japan', 'France'], 35: ['Switzerland', 'Japan', 'Germany'], 36: ['Switzerland', 'Japan', 'Germany'], 37: ['Switzerland', 'Japan', 'Germany'], 38: ['Switzerland', 'Japan', 'France'], 39: ['Switzerland', 'Japan', 'Germany'], 40: ['Switzerland', 'Japan', 'Germany'], 41: ['Switzerland', 'Japan', 'Germany'], 42: ['Switzerland', 'Japan', 'France'], 43: ['Switzerland', 'Japan', 'Germany'], 44: ['Switzerland', 'Japan', 'Germany'], 45: ['Switzerland', 'Japan', 'Germany'], 46: ['Switzerland', 'Japan', 'Germany'], 47: ['Switzerland', 'Japan', 'Germany'], 48: ['Switzerland', 'Japan', 'Germany'], 49: ['Switzerland', 'Japan', 'Germany'], 50: ['Switzerland', 'Japan', 'Germany'], 51: ['Switzerland', 'Japan', 'Germany'], 52: ['Switzerland', 'Japan', 'Germany'], 53: ['Switzerland', 'Japan', 'Germany'], 54: ['Switzerland', 'Japan', 'Germany'], 55: ['Switzerland', 'Japan', 'Germany'], 56: ['Japan', 'Switzerland', 'Germany'], 57: ['Japan', 'Switzerland', 'Germany'], 58: ['Japan', 'Switzerland', 'France'], 59: ['Japan', 'Switzerland', 'Germany'], 60: ['Japan', 'Switzerland', 'Germany'], 61: ['Japan', 'Switzerland', 'Germany'], 62: ['Japan', 'Switzerland', 'Germany'], 63: ['Japan', 'Switzerland', 'Germany'], 64: ['Japan', 'Switzerland', 'Germany'], 65: ['Japan', 'Switzerland', 'Germany'], 66: ['Japan', 'Switzerland', 'Germany'], 67: ['Japan', 'Switzerland', 'Germany'], 68: ['Japan', 'Switzerland', 'Germany'], 69: ['Japan', 'Switzerland', 'Germany'], 70: ['Japan', 'Switzerland', 'Germany'], 71: ['Japan', 'Switzerland', 'Germany'], 72: ['Japan', 'Switzerland', 'Germany'], 73: ['Japan', 'Switzerland', 'Germany'], 74: ['Japan', 'Switzerland', 'Germany'], 75: ['Japan', 'Switzerland', 'Germany'], 76: ['Switzerland', 'Japan', 'Germany'], 77: ['Switzerland', 'Germany', 'Japan'], 78: ['Switzerland', 'Japan', 'Germany'], 79: ['Switzerland', 'Japan', 'Germany'], 80: ['Switzerland', 'Germany', 'Japan'], 81: ['Switzerland', 'Japan', 'Germany'], 82: ['Switzerland', 'Japan', 'Germany'], 83: ['Switzerland', 'Germany', 'Japan'], 84: ['Switzerland', 'Japan', 'Germany'], 85: ['Switzerland', 'Japan', 'Germany'], 86: ['Switzerland', 'Japan', 'Germany'], 87: ['Switzerland', 'Japan', 'Germany'], 88: ['Switzerland', 'Japan', 'Germany'], 89: ['Japan', 'Switzerland', 'Germany'], 90: ['Switzerland', 'Japan', 'Germany'], 91: ['Switzerland', 'Japan', 'Germany'], 92: ['Japan', 'Switzerland', 'Germany'], 93: ['Japan', 'Switzerland', 'Germany'], 94: ['Japan', 'Switzerland', 'Germany'], 95: ['Japan', 'Switzerland', 'Germany'], 96: ['Japan', 'Switzerland', 'Germany'], 97: ['Japan', 'Switzerland', 'Germany'], 98: ['Japan', 'Switzerland', 'Germany'], 99: ['Japan', 'Switzerland', 'Germany'], 100: ['Japan', 'Switzerland', 'Germany'], 101: ['Japan', 'Switzerland', 'Germany'], 102: ['Japan', 'Switzerland', 'Germany'], 103: ['Japan', 'Switzerland', 'Germany'], 104: ['Japan', 'Switzerland', 'Germany'], 105: ['Japan', 'Switzerland', 'Germany'], 106: ['Japan', 'Switzerland', 'Germany'], 107: ['Japan', 'Switzerland', 'Germany'], 108: ['Japan', 'Switzerland', 'Germany'], 109: ['Japan', 'Switzerland', 'Germany'], 110: ['Japan', 'Switzerland', 'Germany'], 111: ['Japan', 'Switzerland', 'Germany'], 112: ['Japan', 'Switzerland', 'India'], 113: ['Japan', 'Switzerland', 'India'], 114: ['Japan', 'Switzerland', 'Germany'], 115: ['Japan', 'Switzerland', 'India'], 116: ['Japan', 'Switzerland', 'Germany'], 117: ['Japan', 'Switzerland', 'Germany'], 118: ['Japan', 'Switzerland', 'Germany'], 119: ['Japan', 'Switzerland', 'Germany'], 120: ['Japan', 'Switzerland', 'Germany'], 121: ['Japan', 'Switzerland', 'India'], 122: ['Japan', 'Switzerland', 'India'], 123: ['Japan', 'Switzerland', 'India'], 124: ['Japan', 'Switzerland', 'Germany'], 125: ['Switzerland', 'Japan', 'Germany'], 126: ['Switzerland', 'Japan', 'India'], 127: ['Switzerland', 'Japan', 'India'], 128: ['Switzerland', 'Japan', 'Germany'], 129: ['Switzerland', 'Japan', 'Germany'], 130: ['Switzerland', 'Japan', 'Germany'], 131: ['Switzerland', 'Japan', 'Germany'], 132: ['Switzerland', 'Japan', 'Germany'], 133: ['Switzerland', 'Japan', 'Germany'], 134: ['Switzerland', 'Japan', 'Germany'], 135: ['Switzerland', 'Japan', 'Germany'], 136: ['Switzerland', 'Japan', 'Germany'], 137: ['Switzerland', 'Japan', 'Germany'], 138: ['Switzerland', 'Japan', 'Germany'], 139: ['Switzerland', 'Japan', 'Germany'], 140: ['Switzerland', 'Japan', 'Germany'], 141: ['Switzerland', 'Germany', 'Japan'], 142: ['Switzerland', 'Germany', 'Japan'], 143: ['Switzerland', 'Germany', 'Japan'], 144: ['Switzerland', 'Germany', 'Japan'], 145: ['Switzerland', 'Germany', 'Japan'], 146: ['Switzerland', 'Germany', 'Japan'], 147: ['Switzerland', 'Germany', 'Japan'], 148: ['Switzerland', 'Germany', 'Japan'], 149: ['Switzerland', 'Germany', 'Japan'], 150: ['Switzerland', 'Germany', 'Japan'], 151: ['Switzerland', 'Japan', 'Germany'], 152: ['Switzerland', 'Japan', 'Germany'], 153: ['Switzerland', 'Japan', 'Germany'], 154: ['Switzerland', 'Germany', 'Japan'], 155: ['Switzerland', 'Germany', 'Japan'], 156: ['Switzerland', 'Germany', 'Japan'], 157: ['Switzerland', 'Germany', 'Japan'], 158: ['Switzerland', 'Germany', 'Japan'], 159: ['Switzerland', 'Germany', 'Japan'], 160: ['Switzerland', 'Germany', 'Japan'], 161: ['Switzerland', 'Japan', 'Germany'], 162: ['Switzerland', 'Germany', 'Japan'], 163: ['Switzerland', 'Germany', 'Japan'], 164: ['Germany', 'Switzerland', 'Japan'], 165: ['Germany', 'Switzerland', 'Japan'], 166: ['Germany', 'Switzerland', 'Japan'], 167: ['Germany', 'Switzerland', 'Japan'], 168: ['Germany', 'Switzerland', 'Japan'], 169: ['Germany', 'Switzerland', 'Japan'], 170: ['Germany', 'Switzerland', 'Japan'], 171: ['Switzerland', 'Germany', 'Japan'], 172: ['Germany', 'Switzerland', 'Japan'], 173: ['Switzerland', 'Germany', 'Japan'], 174: ['Switzerland', 'Germany', 'Japan'], 175: ['Switzerland', 'Germany', 'Japan'], 176: ['Switzerland', 'Germany', 'Japan'], 177: ['Switzerland', 'Germany', 'Japan'], 178: ['Switzerland', 'Germany', 'Japan'], 179: ['Switzerland', 'Germany', 'Japan'], 180: ['Switzerland', 'Germany', 'France'], 181: ['Switzerland', 'Germany', 'France'], 182: ['Switzerland', 'Germany', 'France'], 183: ['Switzerland', 'Germany', 'France'], 184: ['Switzerland', 'Germany', 'France'], 185: ['Germany', 'Switzerland', 'France'], 186: ['Germany', 'Switzerland', 'France'], 187: ['Germany', 'Switzerland', 'France'], 188: ['Germany', 'Switzerland', 'France'], 189: ['Germany', 'Switzerland', 'France'], 190: ['Germany', 'Switzerland', 'France'], 191: ['Germany', 'Switzerland', 'France'], 192: ['Germany', 'Switzerland', 'France'], 193: ['Germany', 'Switzerland', 'France'], 194: ['Germany', 'Switzerland', 'France'], 195: ['Germany', 'Switzerland', 'France'], 196: ['Germany', 'Switzerland', 'France'], 197: ['Germany', 'Switzerland', 'France'], 198: ['Germany', 'Switzerland', 'France'], 199: ['Germany', 'Switzerland', 'France'], 200: ['Germany', 'Switzerland', 'France'], 201: ['Germany', 'Switzerland', 'France'], 202: ['Germany', 'Switzerland', 'France'], 203: ['Germany', 'Switzerland', 'France'], 204: ['Germany', 'Switzerland', 'France'], 205: ['Germany', 'France', 'Switzerland'], 206: ['Germany', 'France', 'Switzerland'], 207: ['Germany', 'France', 'Switzerland'], 208: ['Germany', 'France', 'Switzerland'], 209: ['Germany', 'France', 'Switzerland'], 210: ['Germany', 'France', 'Switzerland'], 211: ['Germany', 'France', 'Canada'], 212: ['Germany', 'France', 'Canada'], 213: ['Germany', 'France', 'Canada'], 214: ['Germany', 'France', 'Canada'], 215: ['Germany', 'France', 'Switzerland'], 216: ['Germany', 'France', 'Canada'], 217: ['Germany', 'France', 'Canada'], 218: ['Germany', 'France', 'Canada'], 219: ['Germany', 'France', 'Canada'], 220: ['Germany', 'France', 'Canada'], 221: ['Germany', 'France', 'Canada'], 222: ['Germany', 'France', 'Canada'], 223: ['Germany', 'France', 'Canada'], 224: ['Germany', 'France', 'Canada'], 225: ['Germany', 'France', 'Canada'], 226: ['Germany', 'France', 'Canada'], 227: ['Germany', 'France', 'Switzerland'], 228: ['Germany', 'France', 'Switzerland'], 229: ['Germany', 'France', 'Canada'], 230: ['Germany', 'France', 'Switzerland'], 231: ['Germany', 'France', 'Canada'], 232: ['Germany', 'France', 'Canada'], 233: ['Germany', 'France', 'Switzerland'], 234: ['Germany', 'France', 'Switzerland'], 235: ['Germany', 'France', 'Switzerland'], 236: ['Germany', 'Switzerland', 'France'], 237: ['Germany', 'Switzerland', 'France'], 238: ['Germany', 'Switzerland', 'Japan'], 239: ['Germany', 'Switzerland', 'China'], 240: ['Germany', 'Switzerland', 'China'], 241: ['Germany', 'China', 'Switzerland'], 242: ['Germany', 'Switzerland', 'China'], 243: ['Germany', 'Switzerland', 'Japan'], 244: ['Germany', 'Switzerland', 'Japan']}\n"
     ]
    }
   ],
   "source": [
    "print(top_bucket)\n",
    "print(bottom_bucket)\n",
    "\n",
    "# avg_yield_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = avg_Carry_1m.iloc[0].drop([\"Switzerland\", np.nan])\n",
    "avg_Carry_1m.iloc[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = avg_yield_countries.iloc[0,2]\n",
    "b = avg_yield_countries.iloc[0,4]\n",
    "np.isnan([\"a\",b]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "p.append(np.nan)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut Momentum Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude Trading Days column and MSCI_EU Benchmark to have only Momentum columns\n",
    "prices = df.loc[:,\"Healthcare\":\"Real_estate\"]\n",
    "prices.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Monthly returns\n",
    "mtl_ret = prices.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "mtl_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_11 = (mtl_ret+1).rolling(11).apply(np.prod)-1 # accumulate returns over 11 months \n",
    "past_11.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining formation date <-  where portfolio gets created\n",
    "formation = dt.datetime(1999, 12, 31, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MeasurementDate <- up to last date of month before formation date\n",
    "end_measurement = formation - MonthEnd(1)\n",
    "end_measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Past 12 Month performance without most recent month <- in this case Jan, Feb, Mar, Apr, Jun, Jul, Sep, Oct, Nov but not December!\n",
    "ret_12 = past_11.loc[end_measurement]\n",
    "ret_12 = ret_12.reset_index()\n",
    "ret_12.rename(columns={ ret_12.columns[1]: \"returns\" }, inplace = True)\n",
    "ret_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_12 = ret_12.sort_values([\"returns\"], ascending=False)\n",
    "ret_12[\"bucket\"] = [2,2,2,2,2,1,0,0,0,0,0] # Make three buckets\n",
    "ret_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create winners and loser list based on bucket\n",
    "winners = ret_12[ret_12.bucket == 2]\n",
    "losers = ret_12[ret_12.bucket == 0]\n",
    "winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the winner and loser returns over the last 12 months excluding the most recent month\n",
    "winnerret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(winners[\"index\"])]\n",
    "loserret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(losers[\"index\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Momentumprofit = winnerret.mean() - loserret.mean()\n",
    "Momentumprofit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalising this Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(pandas_df, index=\"Date\", prices_start='Healthcare', prices_end='Real_estate', resample_freq='M', lookback=11):\n",
    "    print(pandas_df.isnull().values.any())\n",
    "    df = pandas_df.set_index(index, inplace=False)\n",
    "    prices = df.loc[:,prices_start:prices_end]\n",
    "    mtl_ret = prices.pct_change().resample(resample_freq).agg(lambda x: (1+x).prod()-1)\n",
    "    past_11 = (mtl_ret+1).rolling(lookback).apply(np.prod)-1\n",
    "    return prices, mtl_ret, past_11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = dff.set_index(\"Date\", inplace = False)\n",
    "x = dfff.resample(\"M\")\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test out the data_cleaner function\n",
    "\n",
    "prices, mtl_ret, past_11 = data_cleaner(dff, lookback = 3, resample_freq= 'BM')\n",
    "print(f'\\nprices:\\n {prices}, \\nmonthly_return:\\n {mtl_ret}, \\npast_11:\\n {past_11}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_11.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(formation, past_11, num_l_s=5):\n",
    "    end_measurement = formation - MonthEnd(1)\n",
    "    ret_12 = past_11.loc[end_measurement]\n",
    "    ret_12 = ret_12.reset_index()\n",
    "    ret_12.rename(columns={ ret_12.columns[1]: \"returns\" }, inplace = True)\n",
    "    ret_12 = ret_12.sort_values([\"returns\"], ascending=False)\n",
    "    \n",
    "    middle = 11-2*num_l_s\n",
    "    l_s = []\n",
    "    for i in range(num_l_s):\n",
    "        l_s.append(2)\n",
    "    for i in range(middle):\n",
    "        l_s.append(1)\n",
    "    for i in range(num_l_s):\n",
    "        l_s.append(0)\n",
    "    ret_12[\"bucket\"] = l_s # Make arbitrary number of buckets\n",
    "    \n",
    "    winners = ret_12[ret_12.bucket == 2]\n",
    "    losers = ret_12[ret_12.bucket == 0]\n",
    "    winnerret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(winners[\"index\"])]\n",
    "    loserret = mtl_ret.loc[formation + MonthEnd(1), mtl_ret.columns.isin(losers[\"index\"])]\n",
    "    Momentumprofit = winnerret.mean() - loserret.mean()\n",
    "    return Momentumprofit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation = dt.datetime(1999, 12, 31, 0, 0)\n",
    "momentum(formation, past_11) # has to be identical with [35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarker(pandas_df, profits_list):\n",
    "    dff = pandas_df.set_index(\"Date\", inplace=False)\n",
    "    \n",
    "    benchmark = dff[[\"MSCI_EU\"]]\n",
    "    benchmark = benchmark.loc[\"1999-12-31 00:00:00\":\"2022-09-30 00:00:00\"]\n",
    "    \n",
    "    bm_mtl_ret = mtl_ret = benchmark.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "    comparison = pd.DataFrame(bm_mtl_ret)\n",
    "    comparison[\"mom_ret\"] = profits_list\n",
    "    comparison.rename(columns={ comparison.columns[0]: \"bench_ret\" }, inplace = True)\n",
    "    comparison[\"bench_indexed\"] = comparison[\"bench_ret\"].add(1).cumprod()\n",
    "    comparison[\"mom_indexed\"] = comparison[\"mom_ret\"].add(1).cumprod()\n",
    "    print(comparison)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(comparison.index,comparison.mom_indexed, label=\"Momentum\", color=\"red\")\n",
    "    ax.plot(comparison.index,comparison.bench_indexed, label=\"MSCI EU\", color=\"blue\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_ylabel('Monthly Returns')\n",
    "    ax.set_title(\"Momentum long/short 5 sectors monthly rebalancing vs MSCI EU, indexed 31.12.1999\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop for every month  starting at formation date -> creates df with all these dates\n",
    "for i in range(273): # Eig wären es 273 Monate zwischen 31.12.1999 und 31.12.2022 -> stimmt irgendwie ned ganz aber lauft jetzt halt so bis endi august\n",
    "    print(formation + MonthEnd(i))\n",
    "\n",
    "#wären es nicht 276 Monate? has mit emene Zeitspannen-rechner usgrechnet --> gahd ets bis endi november 2022\n",
    "for i in range(276):\n",
    "    print(formation + MonthEnd(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop for storing the profits and the realized dates of the momentum strategy\n",
    "profits = []\n",
    "dates = []\n",
    "\n",
    "'''\n",
    "for i in range(273):\n",
    "    profits.append(momentum(formation + MonthEnd(i)))\n",
    "    dates.append(formation + MonthEnd(i))\n",
    "'''\n",
    "\n",
    "#version 2.0 (da gahds nume bis 274 --> gid en error wenn en monet meh nimmsch)\n",
    "for i in range(274):\n",
    "    profits.append(momentum(formation + MonthEnd(i), past_11))\n",
    "    dates.append(formation + MonthEnd(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarker(df, profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = pd.DataFrame({\"Dates\": dates,\"Profits\": profits})\n",
    "mom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = df[[\"MSCI_EU\"]]\n",
    "benchmark = benchmark.loc[\"1999-12-31 00:00:00\":\"2022-09-30 00:00:00\"]\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_mtl_ret = mtl_ret = benchmark.pct_change().resample(\"M\").agg(lambda x: (1+x).prod()-1) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "bm_mtl_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare momentum result vs benchmark\n",
    "comparison = pd.DataFrame(bm_mtl_ret)\n",
    "comparison[\"mom_ret\"] = profits\n",
    "comparison.rename(columns={ comparison.columns[0]: \"bench_ret\" }, inplace = True)\n",
    "comparison[\"bench_indexed\"] = comparison[\"bench_ret\"].add(1).cumprod()\n",
    "comparison[\"mom_indexed\"] = comparison[\"mom_ret\"].add(1).cumprod()\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(comparison.index,comparison.mom_indexed, label=\"Momentum\", color=\"red\")\n",
    "ax.plot(comparison.index,comparison.bench_indexed, label=\"MSCI EU\", color=\"blue\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_ylabel('Monthly Returns')\n",
    "ax.set_title(\"Momentum long/short 5 sectors monthly rebalancing vs MSCI EU, indexed 31.12.1999\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa336b74a8cbeead930f17f553be49714fc6c4491fbee50d1179d377ec590ae0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
